{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"pytorch-widedeep, deep learning for tabular data II: advanced use\"\n",
    "> a flexible package to combine tabular data with text and images using wide and deep models.\n",
    "\n",
    "- author: Javier Rodriguez\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the second of a series of posts introducing [pytorch-widedeep](https://github.com/jrzaurin/pytorch-widedeep), a flexible package to combine tabular data with text and images (that could also be used for \"standard\" tabular data alone). \n",
    "\n",
    "In the first post I described `pytorch-widedeep`'s data preprocessing utilities, the main components of a `WideDeep` model and a quick example to illustrate the basic use of the library. In this post I will use a series of examples to dig deeper into the many options `pytorch-widedeep` offers as we build wide and deep models.\n",
    "\n",
    "## 1. Binary classification with varying parameters\n",
    "\n",
    "Let's start by using again the [adult census](http://archive.ics.uci.edu/ml/datasets/Adult) dataset. \n",
    "\n",
    "Before moving any further, let me emphasize that, as we go through the examples, one should not pay excessive (or any) attention to the loss or the metrics in the sense that the input parameters are not selected to obtain \"state of the art\", but to illustrate usability. \n",
    "\n",
    "A proper benchmarking exercise will be carried out in a future post. Having said that, and without further ado, let's start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "adult = pd.read_csv(\"data/adult/adult.csv.zip\")\n",
    "adult.columns = [c.replace(\"-\", \"_\") for c in adult.columns]\n",
    "adult[\"income_label\"] = (adult[\"income\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "adult.drop(\"income\", axis=1, inplace=True)\n",
    "\n",
    "for c in adult.columns:\n",
    "    if adult[c].dtype == 'O':\n",
    "        adult[c] = adult[c].apply(lambda x: \"unknown\" if x == \"?\" else x)\n",
    "        adult[c] = adult[c].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>never-married</td>\n",
       "      <td>machine-op-inspct</td>\n",
       "      <td>own-child</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>united-states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>private</td>\n",
       "      <td>89814</td>\n",
       "      <td>hs-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>farming-fishing</td>\n",
       "      <td>husband</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>united-states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>protective-serv</td>\n",
       "      <td>husband</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>united-states</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>private</td>\n",
       "      <td>160323</td>\n",
       "      <td>some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>married-civ-spouse</td>\n",
       "      <td>machine-op-inspct</td>\n",
       "      <td>husband</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>united-states</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>unknown</td>\n",
       "      <td>103497</td>\n",
       "      <td>some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>never-married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>own-child</td>\n",
       "      <td>white</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>united-states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational_num      marital_status  \\\n",
       "0   25    private  226802          11th                7       never-married   \n",
       "1   38    private   89814       hs-grad                9  married-civ-spouse   \n",
       "2   28  local-gov  336951    assoc-acdm               12  married-civ-spouse   \n",
       "3   44    private  160323  some-college               10  married-civ-spouse   \n",
       "4   18    unknown  103497  some-college               10       never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital_gain  capital_loss  \\\n",
       "0  machine-op-inspct    own-child  black    male             0             0   \n",
       "1    farming-fishing      husband  white    male             0             0   \n",
       "2    protective-serv      husband  white    male             0             0   \n",
       "3  machine-op-inspct      husband  black    male          7688             0   \n",
       "4            unknown    own-child  white  female             0             0   \n",
       "\n",
       "   hours_per_week native_country  income_label  \n",
       "0              40  united-states             0  \n",
       "1              50  united-states             0  \n",
       "2              40  united-states             1  \n",
       "3              40  united-states             1  \n",
       "4              30  united-states             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you read the first post you will be familiar with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "from pytorch_widedeep.models import Wide, TabMlp, TabResnet, WideDeep\n",
    "from pytorch_widedeep.metrics import Accuracy, Recall\n",
    "\n",
    "wide_cols = ['education', 'relationship','workclass','occupation','native_country','gender']\n",
    "crossed_cols = [('education', 'occupation'), ('native_country', 'occupation')]\n",
    "cat_embed_cols = [('education',32), ('relationship',32), ('workclass',32), ('occupation',32),('native_country',32)]\n",
    "continuous_cols = [\"age\",\"hours_per_week\"]\n",
    "target_col = 'income_label'\n",
    "\n",
    "# TARGET\n",
    "target = adult[target_col].values\n",
    "\n",
    "# WIDE\n",
    "wide_preprocessor = WidePreprocessor(wide_cols=wide_cols, crossed_cols=crossed_cols)\n",
    "X_wide = wide_preprocessor.fit_transform(adult)\n",
    "\n",
    "# DEEP\n",
    "tab_preprocessor = TabPreprocessor(embed_cols=cat_embed_cols, continuous_cols=continuous_cols)\n",
    "X_tab = tab_preprocessor.fit_transform(adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "# We can add dropout and batchnorm to the dense layers, as well as chose the order of the operations\n",
    "deeptabular = TabMlp(column_idx=tab_preprocessor.column_idx,\n",
    "                   mlp_hidden_dims=[64,32], \n",
    "                   mlp_dropout=[0.5, 0.5], \n",
    "                   mlp_batchnorm=True, \n",
    "                   mlp_linear_first = True,\n",
    "                   embed_input=tab_preprocessor.embeddings_input,\n",
    "                   continuous_cols=continuous_cols)\n",
    "model = WideDeep(wide=wide, deeptabular=deeptabular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look to the model that we will be running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WideDeep(\n",
       "  (wide): Wide(\n",
       "    (wide_linear): Embedding(797, 1, padding_idx=0)\n",
       "  )\n",
       "  (deeptabular): Sequential(\n",
       "    (0): TabMlp(\n",
       "      (embed_layers): ModuleDict(\n",
       "        (emb_layer_education): Embedding(17, 32, padding_idx=0)\n",
       "        (emb_layer_native_country): Embedding(43, 32, padding_idx=0)\n",
       "        (emb_layer_occupation): Embedding(16, 32, padding_idx=0)\n",
       "        (emb_layer_relationship): Embedding(7, 32, padding_idx=0)\n",
       "        (emb_layer_workclass): Embedding(10, 32, padding_idx=0)\n",
       "      )\n",
       "      (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (tab_mlp): MLP(\n",
       "        (mlp): Sequential(\n",
       "          (dense_layer_0): Sequential(\n",
       "            (0): Linear(in_features=162, out_features=64, bias=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (dense_layer_1): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the set up for each model component, including optimizers, learning rate schedulers and initializers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.initializers import KaimingNormal, XavierNormal\n",
    "from pytorch_widedeep.callbacks import ModelCheckpoint, LRHistory, EarlyStopping\n",
    "from pytorch_widedeep.optim import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "wide_opt = torch.optim.Adam(model.wide.parameters(), lr=0.03)\n",
    "deep_opt = RAdam(model.deeptabular.parameters(), lr=0.01)\n",
    "# LR Schedulers\n",
    "wide_sch = torch.optim.lr_scheduler.StepLR(wide_opt, step_size=3)\n",
    "deep_sch = torch.optim.lr_scheduler.StepLR(deep_opt, step_size=5)\n",
    "\n",
    "# Component-dependent settings as Dict\n",
    "optimizers = {'wide': wide_opt, 'deeptabular':deep_opt}\n",
    "schedulers = {'wide': wide_sch, 'deeptabular':deep_sch}\n",
    "initializers = {'wide': KaimingNormal, 'deeptabular':XavierNormal}\n",
    "\n",
    "# General settings as List\n",
    "callbacks = [LRHistory(n_epochs=10), EarlyStopping, ModelCheckpoint(filepath='model_weights/wd_out')]\n",
    "metrics = [Accuracy, Recall]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the trainer and fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, \n",
    "                  objective='binary', \n",
    "                  optimizers=optimizers, \n",
    "                  lr_schedulers=schedulers,\n",
    "                  initializers=initializers,\n",
    "                  callbacks=callbacks,\n",
    "                  metrics=metrics, \n",
    "                  verbose=0,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(X_wide=X_wide, X_tab=X_tab, target=target, n_epochs=10, batch_size=256, val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javier/.pyenv/versions/3.7.9/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'learning rate')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4gAAAHkCAYAAAB8GQHGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACbaUlEQVR4nOzdeXhU5dnH8e+ZNXuGhEkCJIBAAqhsioJooVopyiIUsEVssbZFtFKU16pUtFqrWBVFEGsVrXXBFqwKYhVR1FYLVQERVJAdEpbsO1lmOe8fCQORIAkkmZnk97kumDn7fR5CztzzbIZpmiYiIiIiIiLS5lmCHYCIiIiIiIiEBiWIIiIiIiIiAihBFBERERERkVpKEEVERERERARQgigiIiIiIiK1lCCKiIiIiIgIALZgBxAshYXl+P2nPsNHYmIM+fllTRhR66cyazyVWeOpzBqnNZeXxWLQrl10sMMIO6f7fITW/XPVHFRejacyazyVWeO15jL7rmdkm00Q/X7ztB+Ap3t8W6QyazyVWeOpzBpH5SXHaorn45HzSMOpvBpPZdZ4KrPGa4tlpiamIiIiIiIiAihBFBERERERkVpKEEVERELQihUrGDlyJMOHD2fx4sXHbf/qq6+YMGECV1xxBdOmTaOkpKTO9kOHDnH++eeTlZXVUiGLiEgroARRREQkxGRnZzNv3jxefvllli9fzpIlS9ixY0edfe6//35mzJjBG2+8wRlnnMGzzz4b2Ob3+5k9ezYej6elQxcRkTDXZgepEREJJxUV5ZSVFeHzeZv0vDk5Fvx+f5OesyVZrTZiYlxERrau0UrXrFnD4MGDcblcAIwYMYKVK1cyffr0wD5+v5/y8nIAKioqiI+PD2x75plnGDJkCLt3727RuEVEJPwpQTwFhaVVYFPRiUjLqKgop7S0EJfLjd3uwDCMJju3zWbB6w3PBNE0TTyeaoqKcgFaVZKYk5OD2+0OLCclJbFp06Y6+8yaNYtrr72WOXPmEBkZydKlSwH48ssv+eSTT1i0aFG9TVNPJjEx5vSCr+V2xzbJedoKlVfjqcwaT2XWeC1VZqbfh+n11P6pxvTVvnq9mL5qPFVVVFdWUl1ZhSMmjoSMfk36eeBYynJOwZL3t1NUXs2syecEOxQRaQPKyopwudw4HM5ghxJSDMPA4XDicrkpLs5rVQmiaR4/rPqxHwQqKyuZPXs2zz//PH379uW5557j9ttvZ/78+dx777089thjWCyn1oskP7/stId1d7tjyc0tPa1ztCUqr8ZTmTVeWysz0/SD6QfTrPvq92Nigt8PR16/td+RY9vFOynMK8b0ecDnqXn1HnnvPbquNpnze734PNX4PdX4vDWvNYneMcf7vBh+L4bfg8XvxWLW/qHhv3dLTQulVz1GdFzcKZePxWKc8AvBkEwQV6xYwZNPPonH4+HnP/85V199dWDbli1bmDVrVmC5oKCA+Ph43nzzzRaLLyUhinVbczhc6SUqIiSLUERaEZ/Pi93uCHYYIctudzR509tgS05OZt26dYHlnJwckpKSAsvbtm3D6XTSt29fAH7yk58wf/581q1bR15eHjfccEPguOuuu46FCxfSrVu3lr0JEWl2pt8H3mpMb1Xta3XdZU8V1VWVeKqqqLBBeXklpt+PafprX03M2gTpyDK1yVGdbaZZk0DVHns0kTq6f91EzAS+a52JYdYkaIFXTAyz9hU/BrX7BbbVrquz77H7+Y85vmnmLjzciH29pgUvVjymte77Y169pgUPEXjNmnV+iw3TYgOLDdNqB4sdrHYsNhuGzYFhs2OxObDaHVjtdmx2B1ank7jE9vSKbb6azZDLbo50zH/ttddwOBxMmjSJQYMG0aNHDwB69+7N8uXLgZo+F1deeSX33HNPi8bYM83FGybs2F9M3+6JLXptEWmbmqsZSWvQGstmyJAhPP744xQUFBAZGcmqVav44x//GNjepUsXDh06xK5du+jWrRurV6+mT58+fO973+P9998P7HfJJZfw9NNPk5qaGozbEGmzTL8fvFW1NU5VxyRu1Q1YrknwfNVV+D1V+DxVmJ6jSZ/h82D4qrGYHixmw7oIWAEvcLJ2KH4zkHLhr63TMgPr6qRumObRdUfXG7XrOf4Y08A0jq6DI8uWuvvUvvfXObYmnmPfm7XxHnvtmvjBxILf5Fvrv72PceLz1Mbix4JptWPY7BhWOxb7sQlbzR+b3YHN4cDptOOwW4mwW3E6rDjsFpx2K067ldjaV4fDWrvOgsNuxRKiz6+QSxAb0jH/iKeeeorzzjuPgQMHtmiM3TrFY7UYbMssUoIoInKMyspKDh8uJyFBvxtPR3JyMjNnzmTKlCl4PB4mTpxI3759mTp1KjNmzKBPnz488MAD3HzzzZimSWJiInPmzAl22CJBV1Oj5QPv0eZ8xzYHPLaZ35Gmgcevq9t08Nh9j9/+7fN4wVsN/sa3avBj4DFteLBS5bdRbVrxYKPaPPLeQbUZhce0Uo0Nj2nFZ7GD1QE2R02Nk92J1e7E6qj5Y3NE4IiIxB7hJCEhjrLDHiwWC4bFgsWwgLXm1WKxYFgtWAwDi1HT/NBiGIFX45h1NkvtsnHsPmAcOcYwsFg47vhQ/TLvSJN+M/AXNU1QgSR3HPn5ZcEJLIhCLkFsSMd8gJKSEpYuXcqKFStO6Tqn2wm/R5qL3YdK1dm3kVRejacya7zWVmY5ORZstuablagpzz19+lR+9atpXHTR0EYdd/PN0/n+9y9m3LgJp3Rdi8XS6v7dx4wZw5gxY+qsW7RoUeD9sGHDGDZs2Hee49jaRJFQYZp+8FRheiprXr2VmNWV4K3EDKyveX/kNbDOW/O+yvTiraqsN7ELfMo/DX4s+A0bPsOKDytew1bzemxTwdpmgtWmA4/fQrVpodpnocq0Ul2b6NUkdzXJXE2yV7POtNqxBBK5COzOCBwOO5ERdiKdNiKdViIdNiKdNiJq37dz1ixHOqxERtiIcFixNqKvcVvrg9hQRxJXI/DX0TcWS2gmtc0t5BLEk3XMP2LFihVceumlJCae2rfUp9sJ/+xuiSz79072HyjCYbee8nnaEv1iajyVWeO1xjLz+/3NNtJoU49iWlRUhM9nNvqcc+cuADjlWPx+/3H/7t/VAV9EGsY0/bV92SqPT9aOJHDeKszqipqmknUSu28ngLXHeqsbfH2/YcVrceA1HHiwU42dKuw1yZYvuibh8lvwmBaq/Vaq/AZVPkttEmfFU5vMeev0BbMcs+3YvmFHli3YbDbsVgt2Wz1/rBbsNiuO2mVbnfUWIhxW2jltRDhttUmetTbRsxHlrEnsbFZNRS6hK+QSxJN1zD/ivffeY9q0aS0ZWh1ndUvk1Q92sOtACb26tAtaHCIioeJ3v/st2dmHuOuuWdxww2/44IP38Hg8HDiQxVNP/Y1Dhw7y7LN/ITNzH9XVHs4/fzB33vkHIiIimD79Oi6++AdMmPATJk4cw9ixE/jXv96gsDCffv0GcOed9xJ3GqO1iUj9TNPErCjGX5KDWZKDvzgbf0ku/pJs/CU5UFXe8HMZVnxWJz6LHa/hwGscSeicVPmjqTRtVPhtHMbGYa+Fcq+Vcq+VKtNOlWk7+krNa7VZU2sHEOGoTbJqX2OjHeA3a5M2a50ELqI2UTs+gbPWWW//VmJ35Dw2qxGyzSFFWkLIJYgn65gPNb/MvvrqKwYMGBCkKKH3GYkYwLbMIiWIItLi/rv5IB9vOnja5zGM2oHlvsNFfTtwYZ8OJz3XAw/MZeLEMcyceRvFxUVs3vwF8+Y9Qa9eZ2K1WvnlL3/KXXfdy0UXDSMnJ5tf//pXvPfeSkaPHnfcuT766EOefPIZ/H4/06dfx/Llr/Kzn117Svco0taZfj9meT7+4hz8JTn4S7IxA0lgLnirju5rWPBFtKPM5iLflk6JEUGF30a518Jhr5VSr5WyaguHfdZAIncksTuSzB1hMQwinVYiamvRIpw2IqNtddYlOI7UtFnrNKc8dp3TcfxgHq2xtYhIqAi5BLEhHfMLCgqw2+04ncGbEywm0k5aUgzfZBYFLQYRkVCWmNiegQPPB8Dn8/HXvy6mU6dUysrKyMvLJT7eRW5ubr3Hjh07nnbtEgAYNGgImZn7WixukXBk+jz4S3Mxj0kCj9QEmqV54Pcd3dlqgxg3VRGJFLfvQrYnhn2HI9hW5GBfuRM/Nc0fY6PstIt11jSTjKlJ3mIcNtof2z+uNomLdNQmgMe8d9gsqokTCUMhlyDCyTvmJyYm8t///relwzpOepqLjzYdwOvzqy25iLSoC/s0rFbvZJq6D+Kxjh3J1Gq18t///oclS14GoEePdCorK/D767+2y3W0ZYbNZqu3f7pIW2NWV9Qmfzm1TUJrk8DibMzyQuoMzmKPxBKXhCWhMxUp/cj3x3GgMoqdpU62Fxjk7q4M7O2wW+jUPprU7jEMdseQ6o4m1R1DXLTmXxVpi0IyQQwXPdNcrF6fxd7sUrp3jA92OCIiIeXYmoPNm7/gr39dxKJFz5OW1hmAGTOuD1ZoIiHJNE3MytKavoBH/hRn19YMZmNW1m1SaUTGYcQlYe3QE0tcEhWOBHJ8sew7HMmeAj9ZeeUc3H0YT+2XQIYBye2sdE6OZsjZHejkjiE1KRq3KzJk52MTkZanBPE0pKe5gJp+iEoQRUTAbrdTXn78oBbl5eVYrRacTic+n49Vq97miy8+56yz+gQhSpHQYFaV492zgeyPtlCRs79mUBhPxTF7GBjR7bDEJ2PtOgAjLhlLXBKeyEQOVkWTWeRlf045WQfL2L+5nLIKD1AEFBEf4yDVHUPvLu1IdceQ6o6hQ2KURl4XkZNSgnga4qMdpCREsW1fEZcP6hLscEREgu7yy0fz0EP38dOf/rzO+vPPH8zFF1/KlCmTsFot9Ox5JpdfPpq9e/cEJU6RYDGrK/Du24hnxyf4sr4EvxdrbCKGqxP2lB41zULjkjHikvBHJZJT4iErt5ys3DL276h5zSveEzif02EltX0052S4A01DU5NiiIm0B+8mRSSsGWYb7dhxuvMgHhk9629vb2Hd1lwW3Pw9Nc84CY041ngqs8ZrjWV26NBeUlKa50uo5uyD2JLqKyPNg3hqTvf5CK3z/+HpML1VePdtwrvzE7z7vgCfByO6HbZu52PvPoik3n3YvjufrNyyQDKYlVPOoYJyvL6afwuLYZCSGEWqO7qmaWhtMpgYH9EmP3/oZ6zxVGaN15rL7LuekapBPE0ZaS7+88VB9ueWk5akDyIiIiJSM6qoL/NLPDs/wbv3c/BWYUTGYe81FFv3QViTe5CZU84HG/az/u8ra5uH1mgX6yTVHUOfbgmkumPo5I6mQ2I0dpsGxBOR5qcE8TRlHNMPUQmiiIhI22X6vfj2f12TFO7ZANUVGM4Y7D0uwNb9fKwdeuHxmXyyNYcPV21g54ES7DYLF/brSGpiVCAZjI5Q81ARCR4liKepfXwkiXFOvsks4gfnpgY7HBEREWlBpt+P7+DWmuaju9djVpWBIxJb13Oxdz8fa6czMSw2sgsO8+GHO/l400HKK72kJEQx6QfpXNgnha5pCa22GZuIhB8liE0gI83FV3sKMU1TE8KKiIi0cqbpx3doO96dn+Ld/RlmRQnYnNi6DsDebRDWtLMxrHZ8fj8btufx4ef7+WpPIVaLwYD09lw8oBO9urTTZwYRCUlKEJtAepqLtV9lk1NYQXJCVLDDERERkSZmmib+3N01zUd3fVozMb3Vjq1zP2zdB2Hr3BfD5gSgsLSKf2/cxX++OEBRWTUJcU5+9L0z+F6/jrhinEG+ExGR76YEsQn0rO2H+E1mkRJEERGRVsI0Tfz5+/Du/ATPrs8wS3PBYsOW1gfboB9j69wfwxEJgN80+Xp3AR98vp+N2/MwTZOzuiXwsxGd6Ns9EatFA8yISHhQgtgEUhKiiI2ysy2ziKH9OgY7HBERETkNvsL9NUnhzk8xiw+BYcGaehb2c67A1vUcDGd0YN+yCg8fbzrIhxv3k1NYQUyknRHnpzFsQCeSXJFBvAsRkVOjBLEJGIZBRpqLbZlFwQ5FREREToG/+BCenZ/i3fkp/sIsMAysHXph63sZtjPOxRIRG9jXNE12HSjhg8/38+mWHLw+Pz1S4xl70RkM7OnGbrMG8U5ERE6PEsQmkpHqYv03uRSUVJIQFxHscEREROQk/KW5eHZ+hnfXJ/jz9gJgTcnAOeSn2LoNxBLlqrN/ZbWX/32dzYcb9rMvpwynw8r3+nbg+wM6aaorEWk1lCA2kWPnQxx8VkpwgxERCRNvvbWCV19dyrPPvhjsUKSN8JcX4t31KZ6dn+LP2QmAxd0N5+BJ2LqdhyUm8bhjsnLL+PDz/az58hCV1T5S3TH8bERPBp+ZTKRTH6VEpHXRb7UmkpYUQ6TTqgRRREQkBHn3f031huX4Dm4DTCyJnXGcPxF7t/OxxCUdt7/H62f9Nzl88Pl+tmcVY7ManNcriYsHpNK9U5ymqBCRVksJYhOxWAzSU118o36IItICPNv+i+eb/5z2eQzDwDTN79zH3nMo9owLT3quP/zhTtq3d3PjjTcBcPjwYa644oc8+uhCXn/9n2ze/AWFhQWkpqZxyy2z6Nu3/2nHL9IQpumn8sNFgIHj3HHYu5+PxdWh3n1ziyr4cON+Pt50kNLDHpJckVx5cXcu6tOB2ChHywYuIhIEShCbUEaai0078yk5XE2cHiIi0saMGDGShx+ew69/PQPDMPjoow/p2rUb//rXGwAsXvwKFouV+fMf4S9/Wcif//xMUOOVtsOfuwezvJCI70+t98sOv99k0858Pvh8P1/uygcD+veomdD+zDMSsKi2UETaECWITSgj1QXA9sxizu3pDm4wItKq2TMubFCt3snYbBa8Xn8TRATnnTcIr9fL5s1f0Ldvf959dyUjRozkkksuJSIiAqvVxsGDB4iNjSU3N7dJrinSEN7d68CwYuvSv8764rIq/rPpIP/ZuJ/8kiriYxyMHtKVYf07asA5EWmzlCA2oa4dYrHbLGzLLFKCKCJtjtVqZfjwy1i9ehWdO3fl88/XM3v2PeTk5DB//lz27NlNly5diI2NxzSbJikVORnTNPHs2YC1Yy8MZzSmafLNviI++Hw/G7bl4vOb9O7Sjp9ckk7/9PbYrJrQXkTaNiWITchmtdC9Y5zmQxSRNmvEiJH89rczOOOMbpx77nm0a5fADTf8irFjx/PEE4swDIO3336TXbt2BDtUaSP8RQcwiw9h9voB767L5MPP93Mw/zDRETZ+cG4qw/p3pENi9MlPJCLSRihBbGIZaS5WrNlDRZVXQ1+LSJuTnp6By9WOF1547pjBasqJjIzAMAz27NnNyy+/gNfrDXKk0lZ4d68H4MUtkXy6ZztndIjjFyN7c37vJBx2TWgvIvJtakfRxDLSXJgm7NhfHOxQRESC4rLLRlFeXsZFFw0F4Lbb7uDll1/khz8cxuzZt3L55aMpKiqkuLgouIFKm+DdswHD3Y31+zz88Lw07rpmIBf17aDkUETkBFTF1cS6d4zHajHYlllEn27HT7YrItLaXXXVT7nqqp8Gli+6aBgXXTSszj6TJ08BYOTIMYwcOaZF45O2w1+ahz9vDwU9RuHzm3oui4g0gGoQm5jTYaVrSqzmQxQREQky754NAGz2dMFqMeiRGh/kiEREQp8SxGaQkeZi94ESqj2+YIciIiJhasWKFYwcOZLhw4ezePHi47Z/9dVXTJgwgSuuuIJp06ZRUlICwM6dO5k8eTJjx47lJz/5CVu2bGnp0EOGd896LO06sf6gQfdO8TjVrFRE5KSUIDaDjDQXPr/JrgMlwQ5FRETCUHZ2NvPmzePll19m+fLlLFmyhB076o78ev/99zNjxgzeeOMNzjjjDJ599lkA7rzzTqZOncry5cu5+eabuf3224NxC0HnryjBd2gb/rQB7DtUSu8u7YIdkohIWFCC2AzSU+MxgG1ZRcEORURaCdM0gx1CyGqNZbNmzRoGDx6My+UiKiqKESNGsHLlyjr7+P1+ysvLAaioqCAiomZi9yuvvJKhQ2sGCOrZsycHDx5s2eBDhHfv52Ca7LP3wAQliCIiDaRBappBVISd1KQYzYcoIk3CarXh8VTjcDiDHUpI8niqsVpb1+MsJycHt9sdWE5KSmLTpk119pk1axbXXnstc+bMITIykqVLlwIwfvz4wD4LFizg0ksvbdS1ExNjTiPyo9zu2CY5z6k69P4mbPFutlXE47AXc37fjthtodvENNjlFY5UZo2nMmu8tlhmreuJGkIy0lx8tOkAXp8fm1UVtSJy6mJiXBQV5eJyubHbHRiGEeyQQoJpmng81RQV5RIb27pqh+qrFT32372yspLZs2fz/PPP07dvX5577jluv/12nn766cDxDz30EF988QUvvPBCo66dn1+G3396tbJudyy5uaWndY7TYVZXcHjXF9jPvIQNW3JI7xRHUeHhoMVzMsEur3CkMms8lVnjteYys1iME34hqASxmfRMc7F6fRZ7s0vp3lGjponIqYuMjAaguDgPn69pJ5i3WCz4/f4mPWdLslptxMa2C5RRa5GcnMy6desCyzk5OSQlJQWWt23bhtPppG/fvgD85Cc/Yf78+QB4vV5uv/12srOzeeGFF4iNbXvffnszN4PfS1VKX/b/J4fBZyYHOyQRkbChBLGZpKe5ANieWawEUUROW2RkdLMkQa3529FwNmTIEB5//HEKCgqIjIxk1apV/PGPfwxs79KlC4cOHWLXrl1069aN1atX06dPHwAefPBBysrK+Otf/4rD4QjWLQSVd896jIhYvqlMBHLo3SUh2CGJiIQNJYjNJD7aQXJCFNsyi7hsUOdghyMiImEkOTmZmTNnMmXKFDweDxMnTqRv375MnTqVGTNm0KdPHx544AFuvvlmTNMkMTGROXPmUFBQwOLFi0lNTeXKK68MnG/58uVBvJuWZfo8ePd9gb37+WzdV0yk00qXlKbpVyki0hYoQWxGPdPiWbc1F79pYlGfIRERaYQxY8YwZsyYOusWLVoUeD9s2DCGDRt23HFff/11s8cWynz7vwZPJbau57Ll7UIyUl1YLRoLQESkofQbsxllpLk4XOVlf255sEMRERFpE7x71oM9gpLYbmQXVmh6CxGRRlKC2IwyavsharoLERGR5mf6/Xj3fI6tcz+2ZJUB0EsJoohIoyhBbEbt4yNJiHMqQRQREWkBvuztmJWl2Lqey9a9hcRE1sxLLCIiDacEsZllpLnYlllU75xWIiIi0nS8u9eD1YY19Wy27iukV2eXxgAQEWkkJYjNLCPNRXF5NTmFFcEORUREpNUyTRPvnvVYO51F3mHIL6lS81IRkVOgBLGZ9azth/iNmpmKiIg0G3/+PsyyfGxdz2HL3kIADVAjInIKlCA2s5SEKGKj7OqHKCIi0oy8e9aDYWDrMoAtewuJj3GQkhAV7LBERMJOSCaIK1asYOTIkQwfPpzFixcft33Xrl387Gc/44orruCXv/wlxcXFQYiyYQzDICPVpQRRRESkGXl3r8eakoEREcvWfUX07tIOQ/0PRUQaLeQSxOzsbObNm8fLL7/M8uXLWbJkCTt27AhsN02TG264galTp/LGG2/Qu3dvnn766SBGfHIZaS7yiispKKkMdigiIiKtjr/4EP7C/di6nsuB/MOUlFfTu7Oal4qInIqQSxDXrFnD4MGDcblcREVFMWLECFauXBnY/tVXXxEVFcXQoUMBuP7667n66quDFW6DaD5EERGR5uPZvQEAW9dz2Frb/1AD1IiInJqQSxBzcnJwu92B5aSkJLKzswPL+/bto3379tx+++2MGTOGu+++m6io0O5jkJYUQ6TTqgRRRESkGXj3rMfSvguW2PZs2VtI+/gI3K7IYIclIhKWbMEO4Nvqmy/w2D4EXq+XTz/9lJdeeok+ffrw2GOP8ac//Yk//elPjbpOYuLpT5zrdsc2eN8zz0hk58HSRh3TGrX1+z8VKrPGU5k1jspLwpm/vBB/zk4cA8fj95t8s6+QARnukx8oIiL1CrkEMTk5mXXr1gWWc3JySEpKCiy73W66dOlCnz59ABg9ejQzZsxo9HXy88vw+0998nq3O5bc3NIG7981OYb1W3PYuTefuCjHKV83nDW2zERldipUZo3TmsvLYjGa5MtACW3ePbXNS884l8ycMsorvZreQkTkNIRcE9MhQ4awdu1aCgoKqKioYNWqVYH+hgADBgygoKCArVu3AvD+++9z1llnBSvcBuuZVvOw2p4ZuiOuioiIhBvvng0Y8SlYXB0D8x/20gA1IiKnLCRrEGfOnMmUKVPweDxMnDiRvn37MnXqVGbMmEGfPn144oknuPPOO6moqCAlJYWHHnoo2GGfVNcOsdhtFrZlFnFuTzV9EREROV1mVTm+A1tx9B2BYRhs3VdISkIU7WKdwQ5NRCRshVyCCDBmzBjGjBlTZ92iRYsC7/v168c///nPlg7rtNisFrp3jNNANSIiIk3Eu3cjmD5sZwzE6/PzTWYRQ85KCXZYIiJhLeSamLZmGWku9uWUUlHlDXYoIiIiYc+7Zz1GdDss7q7sOVRKVbVP/Q9FRE6TEsQWlJHmwjRhx371QxQRETkdprcKb+aX2Lqcg2FYAv0Pe3Z2BTcwEZEwpwSxBXXvGI/VYqiZqYiIyGnyZn4JvmpsZ5wLwNa9haQlxRDbRkcKFxFpKkoQW5DTYaVLSizfKEEUERE5Ld4968EZjbVDBh6vjx37izV6qYhIE1CC2MIy0lzsOVhCtccX7FBERETCkun34t27EVuX/hgWGzv3l+Dx+tX/UESkCShBbGEZaS68PpPdB0uCHYqIiEhY8h3YCtWHsXWtaV66ZW8hhlHzjBURkdOjBLGFpafGY4CamYqItGKbN28OdgitmnfPBrA5sKWeDcCWfYV0TYkjKiIkZ+8SEQkrShBbWHSEndSkGA1UIyLSil1//fWMGDGChQsXsm/fvmCH06qYph/vng3YUvtg2BxUVfvYfaBEzUtFRJqIEsQgyEh1sWN/MV6fP9ihiIhIM/joo4+488472b9/P+PHj+fHP/4xL774IgUFBcEOLez5c3ZhHi4KjF66PasIn9+kVxdXcAMTEWkllCAGQUZnF9UeP/uyy4IdioiINAOLxcL3vvc9HnjgAdasWcN1113Hq6++ytChQ5k6dSqrVq0Kdohhy7tnAxhWbJ37ATX9D60Wg/ROruAGJiLSSqixfhBkpMYDsC2ziG4d44IcjYiINAe/38+aNWt46623WL16NW63m9/85jd07NiRJ598knfffZeHH3442GGGFdM08exej7VTbwxnNFCTIHbvGIfTYQ1ydCIirYMSxCCIj3GSnBDFtswiLhvUOdjhiIhIE7vrrrt49913cTgcjBo1ir/97W/07t07sL1Hjx5Mnjw5iBGGJ3/hfsySbGx9RwBwuNLD3uxSxgzpGtzARERaESWIQZKRGs+Gbbn4TROLYQQ7HBERaUI+n4/HHnuMQYMGYdTzOz4tLY0XXnghCJGFN++e9YCBres5QM2I4KaJBqgREWlC6oMYJBlpLsorvRzILQ92KCIi0sTuuece1q5dS1ZWFgAvvfQS8+fPx+v1AhATE0OfPn2+8xwrVqxg5MiRDB8+nMWLFx+3/auvvmLChAlcccUVTJs2jZKSmvl1S0pKuO6667j88su5+uqryc3NbeK7Cx7v7g1YkrtjiXIBNc1L7TYL3TrGBzcwEZFWRAlikPSsncxX8yGKiLQ+99xzD1988QUOhwOA/v37s3HjRh544IEGHZ+dnc28efN4+eWXWb58OUuWLGHHjh119rn//vuZMWMGb7zxBmeccQbPPvssAI899hgDBw7k7bff5sorr+T+++9v2psLEn9JLv78vdi7nhtYt3VvIemp8dht+jgjItJU9Bs1SBLjI0iIc2o+RBGRVuj999/niSeeIDk5GYCzzz6bBQsW8Pbbbzfo+DVr1jB48GBcLhdRUVGMGDGClStX1tnH7/dTXl7TCqWiooKIiAgAPvzwQ8aMGQPA6NGj+c9//oPH42mqWwsa754NAIHpLUrKq8nKLVfzUhGRJqY+iEFiGAYZaS627CnENM16+6iIiEh4MgyDiooKoqOjA+uqq6uxWhs20mZOTg5utzuwnJSUxKZNm+rsM2vWLK699lrmzJlDZGQkS5cuPe5Ym81GTEwMBQUFgWT1ZBITYxq038m43bFNcp4jDuzfiCOpM8nduwOwdf9+AC7o16nJrxUMreEeWprKrPFUZo3XFstMCWIQZaS6+N9X2eQUVpCcEBXscEREpImMGjWKX//619xwww0kJyeTnZ3NU089xejRoxt0vGmax6079ovEyspKZs+ezfPPP0/fvn157rnnuP3223n66afrPZ/F0vAGQ/n5Zfj9x1+/MdzuWHJzS0/rHMfyV5RQmbkVxzlXBM776ZcHiXBYiY+wNum1gqGpy6stUJk1nsqs8VpzmVksxgm/EFQT0yDKqO2HqGamIiKty2233cb555/PH//4RyZNmsScOXMYMmQIM2fObNDxycnJ5OXlBZZzcnJISkoKLG/btg2n00nfvn0B+MlPfsKnn34K1NQ2HjnW6/VSVlaGy+VqojsLDu/ezwEz0LwUagaoyUhzYW1E8isiIien36pB1CExiphIuxJEEZFWxuFw8Nvf/pb333+fTZs28e677zJjxozAoDUnM2TIENauXUtBQQEVFRWsWrWKoUOHBrZ36dKFQ4cOsWvXLgBWr14dGBV12LBhLFu2DIC33nqLgQMHYrfbm/YGW5h393qMWDeWhDQACkoqyS44rP6HIiLNQE1Mg8gwDHqmuTSSqYhIK1NQUMBLL71EdnY2fr8fqKnN27lzJ6+99tpJj09OTmbmzJlMmTIFj8fDxIkT6du3L1OnTmXGjBn06dOHBx54gJtvvhnTNElMTGTOnDkA3HTTTcyaNYtRo0YRGxvL3Llzm/Vem5tZXYFv/9fYz/pBoJnt1n2FgOY/FBFpDs2WIBYVFfHiiy/ym9/8hk2bNjFr1ixcLhcPPPAAXbp0aa7Lhp30NBfrt+VSUFJJQlxEsMMREZEmcOutt1JaWkq7du0oLCykR48erF69mkmTJjX4HGPGjAmMRnrEokWLAu+HDRvGsGHDjjvO5XLxl7/85dSDDzHefV+A33tc89LoCBupSU0zoI6IiBzVbE1Mf//737N582ZM0+See+7hwgsv5LzzzuOuu+5qrkuGpZ7qhygi0ups2LCBRYsWMXPmTOLi4pgzZw7z5s1j48aNwQ4t7Hj3bMCIjMOa1AOoGcBn695CenVph0UjgIuINLlmq0HcuHEj7777LocOHeKbb77hueeeIzY2lvPOO6+5LhmW0pJiiHBY2ZZVzOCzUoIdjoiINIHo6Gji4+NxOBxs27YNqKnxu+2224IcWXgxvdV4Mzdh7z4Yo3YwmtziSvJLqrhskJqXiog0h2arQayurgbggw8+4MwzzyQ+Pp7CwkKcTmdzXTIsWSwG6aku1SCKiLQi6enpLF68mIiICKKioti8eTPbt29v1HQTAr79X4OnEtsZ5wTWbd2r/ociIs2p2WoQL7nkEq655hr27NnDzTffzO7du7nlllsYMWJEc10ybGWkxfPqv/MpOVxNXFTDRrgTEZHQdeutt3LzzTczdOhQpk+fzlVXXQXAr3/96yBHFl68e9aDPRJrxzMD67bsLSQ+2kGHRM0fLCLSHJotQfzDH/7A8uXLcTqdjBkzhr179zJ69GimTJnSXJcMW0fmQ9yeWcy5Pd3BDUZERE5beXk5b7/9NlarlbS0NM477zzKy8vp1q1bsEMLG6bfh3fvRmyd+2FYaz6umKbJlr2FnNmlXWBEUxERaVrNliDa7XYuv/xyoqOj8fl8fPXVV/Tu3RubTTNrfFvXlDjsNgvbs4qUIIqItALTp0/nP//5D1arFaiZtkIax3doO2ZlaZ3RSw/mH6akvJpeal4qItJsmq0zxBtvvBGY1Hfu3Lncf//93HrrrTz99NPNdcmwZbdZ6N4xTvMhioi0Ev369ePtt9/G4/EEO5Sw5d2zHqw2bGl9Auu21PY/VIIoItJ8mq0675lnnuGJJ57A4/GwdOlSnn32WdxuN1dddRXXXXddc102bGWkuVixZg8VVV4inaplFREJZ1lZWcyaNYvZs2cTGxtbpznk2rVrgxhZeDBNE++eDVg7nY1hPzpH8Na9hSTGReCO17zBIiLNpdkykUOHDjF48GD+97//ERERQf/+/QEoKytrrkuGtfQ0F6YJO/YX06dbYrDDERGR03DPPfcEO4Sw5s/bi1mWj/3ccUfXmSZb9xUyIN2t/ociIs2o2RLElJQU3n33XVasWMGFF14IwCuvvELXrl2b65JhrUfHeKwWg22ZRUoQRUTC3Pnnnx/sEMKad896MCxYu/QPrMvMLqO80qvpLUREmlmzJYizZs3ijjvuwOl08uyzz7JmzRrmzp3LwoULm+uSYc3psNIlJVbzIYqItAK9evU6YS3Xli1bWjia8OPdsx5rh55YImID67buU/9DEZGW0GwJ4pAhQ/jwww8Dy8nJyXz88cfY7fbmumTYy0hz8d66TKo9Phx2a7DDERGRU7RixYo6y4WFhTz//PN8//vfD05AYcRfdBB/4QGcvS+us37L3kKSE6JoF+sMUmQiIm1Ds46GsmTJEl5//XUOHTpEYmIiV1xxBddcc01zXjKsZaS5WPnJPnYfLKFnZ31DKiISrtLT049bd+aZZzJ27FiuvPLKIEQUPjx71gNg63pOYJ3X5+ebzCIuOCslWGGJiLQZzTqK6ZIlS/jVr35Fx44dyczM5K9//StVVVUaxfQE0lPjMYBvMouUIIqItDKHDx+mvLw82GGEPO/uDVjcZ2CJOdoff++hUqqqfep/KCLSApotQVyyZAlPPfUU3bp1C6wbNGgQv/jFL5QgnkB0hJ1O7hi2qx+iiEhYmzFjRp0+iB6Ph02bNnHxxRd/x1HiLyvAn7sLx3kT66w/Mv9hz86uIEQlItK2NFuCWFxcTOfOneusS0tLo6Kiorku2Sr0THPx8eaDeH1+bFZLsMMREZFTkJGRUWfZYrEwevRohg8fHqSIwoN3zwYAbGecU2f91n2FpLpjiItyBCMsEZE2pdkSxHPOOYf58+czc+ZMLBYLfr+fBQsWBOZDlPpldHaxekMW+7LL6NYxLtjhiIjIKZg+fTq7d+8mKSmJ6OhoNm3aRExMjAZqOwnvnvVYXB2wujoG1nm8frZnFTOsf8fvOFJERJpKs1VR3XHHHbz11ltccMEFjBkzhgsuuIAPPviAO++8s7ku2SpkpMYDaLoLEZEwtmLFCiZMmEBmZiYAX375JVdddRXvvfdekCMLXWZlGb6D32Drem6d9bsOFOPx+tX/UESkhTRbDWLnzp1ZuXIl69ato6CggA4dOtC3b19stmYdODXsxcc4SW4XybbMIi4b1PnkB4iISMhZsGABzz//PL169QJg8uTJnH322dx2221ceumlQY4uNHn3bQTTj+2Mugnilr2FGEZNFwwREWl+zdrJzW63c8EFFzBq1CjOOeccSkpKuPrqq0963IoVKxg5ciTDhw9n8eLFx21fuHAhF198MWPHjmXs2LH17hPOMtJcbM8qwm+awQ5FREROQX5+Pr17966z7qyzziI/Pz9IEYU+7+71GNEJWNp3rbN+y95CuqbEEhWh5rkiIi2hRavzPB4PGzZs+M59srOzmTdvHq+99hoOh4NJkyYxaNAgevToEdjnyy+/5NFHH2XAgAHNHXJQZKS5+GjTQQ7klpOaFBPscEREpJHOOussFi1axA033BBY9+yzz3LWWWcFMarQZXqq8GZ9ib3XsDqjv1ZV+9h1oIQfnp8WxOhERNqWkGvvuWbNGgYPHozL5QJgxIgRrFy5kunTpwf2+fLLL1m0aBGZmZmcd9553H777TidziBF3PSONKP5JrNICaKISBj6/e9/z7Rp03jhhRdwu93k5OQQHx/PX/7yl2CHFpK8mZvA5zmueen2/UX4/Ca9NTewiEiLCbkEMScnB7fbHVhOSkpi06ZNgeXy8nJ69+7N7bffTqdOnZg1axZ//vOfmTlzZqOuk5h4+omX2x172ueoT/v2MbSPj2BvTlmzXSNYWtv9tASVWeOpzBpH5dX00tPTeeedd9iwYQP5+fkkJSXRr18/jWJ6At49GzCcMVhT6k4PsmVvIVaLQXqqKziBiYi0QU2eIO7YseOE23Jzc096vFlPv7tjm5tER0ezaNGiwPIvfvEL7rjjjkYniPn5Zfj9p97Hz+2OJTe39JSPP5keneLZvDOPnJySOvcfzpq7zFojlVnjqcwapzWXl8ViNMmXgaeiqKiI++67jxtuuIFBgwaxcOFCli5dyu9//3tiYtQy5Fimz4t330ZsXQdiWKx1tm3dW0i3jnE4HdYTHC0iIk2tyRPE0aNHYxhGvYkecNJkJzk5mXXr1gWWc3JySEpKCiwfOHCANWvWMHHiRKAmoWyNI6NmpLn439fZ5BRVkNwuKtjhiIhII9x5551ERESQmJgIwLhx41iwYAF33303jzzySJCjCy2+g1uhugL7GefUWX+40sueQ6WMGdI1OIGJiLRRTZ5Zbd269bSOHzJkCI8//jgFBQVERkayatUq/vjHPwa2R0RE8PDDDzNo0CBSU1NZvHgxw4cPP92wQ05GbT/EbfuKlCCKiISZTz/9lP/+97+BJqWpqan88Y9/ZOjQoUGOLPR4d68DmxNrp7oD+GzLLMI00fyHIiItrFmnuTgVycnJzJw5kylTpjBu3DhGjx5N3759mTp1Kps3byYhIYF7772XG264gcsuuwzTNLn22muDHXaT65AYRUyknW2ZRcEORUREGikiIoIDBw7UWZeTk0N0dHSQIgpNpunHu+dzbGl9MGyOOtu27C3EbrPQrWN8kKITEWmbQrJt5pgxYxgzZkyddcf2OxwxYgQjRoxo6bBalGEYZKS5+EYJoohI2Pnxj3/M1KlT+dnPfkZKSgrZ2dm8+OKLTJo0KdihhRR/9k7MiuLjRi+FmgSxR6d47LaQ+y5bRKRVC8kEUWpkpLnYsC2XgpJKEuIigh2OiIg00I033khiYiJvvfUWeXl5pKSk8OMf/xifzxfs0EKKZ896sFixde5XZ33J4WqycssYP7RbkCITEWm79LVcCDsyH+K2rKKgxiEiIo1jGAZXXXUVL774InPnziUlJYX58+fz8ssvBzu0kGGaJt7d67F2OhPDUbev/Tf7igD1PxQRCQbVIIawtKQYIhxWtmUWM/jMlGCHIyIiDeT1elm5ciUvvfQSX3zxBZdffjlPPvkkQ4YMafA5VqxYwZNPPonH4+HnP/85V199dWDbli1bmDVrVmC5oKCA+Ph43nzzTbKysrj99tspKysjLi6OP/3pT3Tq1KlJ768p+AuyMEtzsfUfddy2rXsLiXBY6dpBc3SKiLQ0JYghzGIx6JEar4FqRETCRG5uLn//+99ZunQpCQkJTJo0iT179jB79uzAlBcNkZ2dzbx583jttddwOBxMmjSJQYMG0aNHDwB69+7N8uXLAaioqODKK6/knnvuAWD+/PmMGjWKyZMn8+KLLzJv3jzmzp3b5Pd6urx71gMGti4Djtu2ZW8hGWkurBY1dBIRaWn6zRvieqa5OJBXTunh6mCHIiIiJ3HxxReTmZnJwoULeeONN5g8efIpzdW7Zs0aBg8ejMvlIioqihEjRrBy5cp6933qqac477zzGDhwIAB+v5+ysjKgJnmMiAjNPuzePeuxpqRjiao7SmlhaRWHCg7Tq7Oal4qIBINqEEPckfkQt2cVc06GO7jBiIjId7r88sv5z3/+Q0VFBRMnTmTYsGGndJ6cnBzc7qO/85OSkti0adNx+5WUlLB06VJWrFgRWHfTTTcxadIkXnzxRTweD0uWLGnUtRMTY04p5m9zu0/cPNRTeIjS/EwSLr0G17f2+7K2/+GQ/p2+8xytTVu616aiMms8lVnjtcUyU4IY4rqmxGG3WdiWWaQEUUQkxD388MOUlJSwbNkyHnnkEe655x5KS0vJzMxsVBNT0zSPW2cYxnHrVqxYwaWXXlrn3Lfffjv33nsvl156Ke+88w7Tp0/njTfeqPf4+uTnl+H3H3/9xnC7Y8nNLT3h9upN/wGgqv3Zx+336eaDREfYiHFYvvMcrcnJykuOpzJrPJVZ47XmMrNYjBN+IagmpiHObrPQrUOc5kMUEQkTcXFxTJkyhRUrVvDoo49y+eWX8/Of/5xx48bxzDPPNOgcycnJ5OXlBZZzcnJISko6br/33nuPkSNHBpYLCgrYtWsXl156KVAzb3Bubi6FhYWneVdNy7t7A5bENCxxx3/xuXVfIb06t8PSwIRWRESalhLEMJCR5mJfdikVVd5ghyIiIo1wzjnn8Kc//YmPP/6YiRMn1mkK+l2GDBnC2rVrKSgooKKiglWrVjF06NA6+5imyVdffcWAAUcHeWnXrh1Op5N169YBsH79eqKjo0lISGi6mzpN/sPF+LJ3YOt67nHbcosqyCuupJemtxARCRo1MQ0DGZ1dmGtg5/5izu7W8CZKIiISGmJiYvjpT3/KT3/60wbtn5yczMyZM5kyZQoej4eJEyfSt29fpk6dyowZM+jTpw8FBQXY7XacTmfgOMMwWLhwIX/84x+prKwkOjqaxx9/vLlu65R4934OmNjOOD5B3LK3pqZTCaKISPAoQQwDPTrGY7UYfJNZpARRRKSNGDNmDGPGjKmzbtGiRYH3iYmJ/Pe//z3uuL59+/LKK680e3ynyrtnPUZcEpZ2qcdt27q3kLhoBx0To4IQmYiIgJqYhgWnw0qXlFjNhygiImHNrD6Mb//X2Lqec9ygOaZpsmVvIb27tGvwgDoiItL0lCCGiYxUF7sPllDt8QU7FBERkVPi3fcF+H3Y6+l/eKjgMMXl1fRW81IRkaBSghgmMtJceH0muw+WBDsUERGRU+LdvR4jMh5Lcvfjtqn/oYhIaFCCGCbS0+IxQM1MRUQkLJnearyZm2ublx7/8WPL3kIS45y44yOCEJ2IiByhBDFMREfY6eSOUYIoIiJhyZf1FXir6h291G+abN1bSC/1PxQRCToliGEkIy2eHftL8Pr8wQ5FRESkUTx71oMjEmuHXsdty8opo7zSq/6HIiIhQAliGMlIc1Hl8bEvuyzYoYiIiDSY6ffh27sRW+f+GNbjZ9jaeqT/YWcliCIiwaYEMYxkpLkA9UMUEZHw4ju0DbOqrN7mpVDT/zA5IYqEOPU/FBEJNiWIYcQV4yS5XaQSRBERCSve3evBaseW2ue4bT6/n28yi+jd2dXygYmIyHGUIIaZjDQX27OK8JtmsEMRERE5KdM08e7ZgC31bAy787jtew6VUlnt0/QWIiIhQglimMlIc1Fe6eVAbnmwQxERETkpf+5uzPKCEzYvVf9DEZHQogQxzBzph/iNmpmKiEgY8O7ZAIYFW+f+9W7fureQVHc0cdGOlg1MRETqpQQxzLSPj6BdrJPtWUXBDkVEROSkvHvWY+3YCyMi5rhtHq+f7VnFal4qIhJClCCGGcMw6Jnm4pvMIkz1QxQRkRDmKzyAv+ggtq7n1Lt914Fiqr1+eqt5qYhIyFCCGIbS01wUl1WTU1QR7FBEREROyLtnPQC2riee3sIwoKdGMBURCRlKEMNQYD7EfUVBjUNEROS7ePdswOLuhiW6/hrCrXsL6ZIcS1SEvYUjExGRE1GCGIY6JkYRE2lnm/ohiohIiPKX5ePP3X3C0UurPD52Hiiht/ofioiEFCWIYcgwDDLSXGzTSKYiIhKivHs2AGA/QfPSHVnF+PymEkQRkRCjBDFMZaS5yC2qpKCkMtihiIiIHMe7ez2Wdh2xuFLq3b5lbyFWi0GP1PgWjkxERL6LEsQwlZFW80BVM1MREQk1vsMl+A59c8LBaaAmQTyjYxwRDlsLRiYiIiejBDFMpSXFEOGwsi2zONihiIiI1HF4+zowzRMmiIcrvew5VKLpLUREQpC+tgtTVouFHqnxbFc/RBERCTHl33yCEZOIpX2XerdvyyrCNFH/QxFpEhUV5ZSVFeHzeZv0vDk5Fvx+f5Oes+UYOBwRtGvnxjCMRh2pBDGM9Uxz8eq/d1F6uJrYKEewwxEREcH0VFKx6wtsvb9/wg8lW/cWYrdZ6N4proWjE5HWpqKinNLSQlwuN3a7o9HJ0Hex2Sx4veGZIJqmn6KiPMrKiomNdTXqWDUxDWPpqS4AtmepmamIiIQGb+YmTJ/npP0Pe3SKx26ztmBkItIalZUV4XK5cTicTZochjvDsBAb246KirJGH6sEMYyd0SEOm9Wi6S5ERCRkeHdvwBIVhzUlo97tpYerycwpo5eal4pIE/D5vNjtaklXH6vVht/va/RxShDDmN1moXvHOCWIIiISEkyfF+++L4hOPw/DUv9HjG/2FQHqfygiTUc1h/U71XJRghjmMtJc7M0upaKqaTvlioiINJbpqQDTT0zfYSfcZ8u+QpwOK11TYlswMhERaSgliGEuo7ML04Sd+9UPUUREgssSEUvMz58gsvNZJ9xn695Ceqa5sFn1EURE2pbKykoKCvKDHcZJ6bdzmOveMQ6LYfCNmpmKiEgIMCwnHiC9sLSKg/mH6aX5D0WkDbrxxqls2fJ1o4+75ZYZLF/+WjNEVL+QTBBXrFjByJEjGT58OIsXLz7hfh9++CGXXHJJC0YWeiIcNrqkxKofoohIK/Ndz8ItW7YwduzYwJ/vfe97jB49GoCcnByuu+46xo0bx6RJk8jKygpG+PXauq8QUP9DEWmbiouLTum4Rx5ZwNix45s2mO8QcvMgZmdnM2/ePF577TUcDgeTJk1i0KBB9OjRo85+eXl5PPjgg0GKMrT0THPx3vpMPF6fhgwXEWkFTvYs7N27N8uXLwegoqKCK6+8knvuuQeA2267jREjRnDVVVfx97//nblz5/LYY48F6U7q2rK3kOgIG2lJMcEORURaqf9uPsjHmw42ybkMA0zzxNsv6tuBC/t0aNC5fve735KdfYi77prFDTf8hg8+eA+Px8OBA1k89dTfOHToIM8++xcyM/dRXe3h/PMHc+edfyAiIoLp06/j4ot/wIQJP2HixDGMHTuBf/3rDQoL8+nXbwB33nkvcXFNN69syNUgrlmzhsGDB+NyuYiKimLEiBGsXLnyuP3uvPNOpk+fHoQIQ09Gmguvz2TXgZJghyIiIk2goc9CgKeeeorzzjuPgQMHUlBQwNatW5k0aRIAEyZM4Oabb27ByL/b1r2F9OzcDotFIw6KSNvywANzSU5O4Y9//BPR0dFs3vwF06bdyJIly0lMbM/s2bdy9dXX8Oab7/HSS0vZuvVr3nuv/t/7H330IU8++Qwvv/wqmZn7WL781SaNNeRqEHNycnC73YHlpKQkNm3aVGefF154gTPPPJN+/fqd8nUSE0//20u3OzRGYBsc7WTBq5vYX1DBRed2DnY43ylUyiycqMwaT2XWOCqv0NOQZyFASUkJS5cuZcWKFQBkZmbSsWNH5syZwyeffELHjh256667GnXtpng+wvE/V4fyy8krrmTCJen6mauHyqTxVGaN1xrLLCfHgs12tM5r2IBODBvQKYgRfTer1cBiMWjfvj2DBw8GwOfz8fzzL5OamkZZWSmFhfm4XC7y8/Ow2SwYRs0xR+5z/PgJuN3tAbjgggvZvz+zThkcy2KxNPrfPeQSRLOeetxj5/DYtm0bq1at4m9/+xuHDh065evk55fh939HnfFJuN2x5OaWnvLxTS3VHc3nW7O5pH/HYIdyQqFWZuFAZdZ4KrPGac3lZbEYTZbstLSTPQuPWLFiBZdeeimJiYkAeL1evv76a37zm98we/ZsXnnlFWbNmsWLL77Y4Guf7vMR6v+5WvPFAQBSEyJb7c/cqWrN/w+bi8qs8Vprmfn9frxef7Oc22azNPm5fT4Tv9+kXbvEY85t8J///JslS14GoEePdCoqKvB6fXi9fkyz5pgj+8fGugLvLRYrPt+Jy8Dv99f77/5dz8iQa2KanJxMXl5eYDknJ4ekpKTA8sqVK8nNzWXChAlcd9115OTkMHny5GCEGlIy0lzs2F+Cz988/0FERKTlnOxZeMR7773HyJEjA8tut5vo6GguvvhiAEaPHl1vzWMwbNlXSFyUnY7to4MdiohI0B37pd/mzV/w178u4rHH/syrr77Jgw/OIzGxfdBiC7kEcciQIaxdu5aCggIqKipYtWoVQ4cODWyfMWMG77zzDsuXL+fpp58mKSmJl19+OYgRh4aMNBdVHh/7ssuCHYqIiJymkz0LoaaW8auvvmLAgAGBdZ07dyY5OZl///vfAHzwwQecddaJ5yRsKaZpsmVvIb26tKu3JlREpC2w2+2Ul5cft768vByr1YLT6cTn8/H222/yxRef4/V6gxBlCCaIycnJzJw5kylTpjBu3DhGjx5N3759mTp1Kps3bw52eCErI80FwDf7ioIah4iInL6GPAsLCgqw2+04nc46xy5cuJBnnnmG0aNH88ILLzBnzpxg3EIdhwoOU1xWrektRKRNu/zy0Tz00H3k5GTXWX/++YO5+OJLmTJlEldc8UPeffcdLr98NHv37glKnIZZX0eHNqC19UEEmPXUWjomRjNjYt9gh1KvUCyzUKcyazyVWeO05vIK5z6IwdQcfRA/2JDFi6u28adpg0lqF3W6IbY6rfn/YXNRmTVeay2zQ4f2kpLSpVnO3Rx9EFvaiconrPogyqnLSHOxPasIf9vM+UVEJERt2VtIQpwTtysy2KGIiMhJKEFsRXp1dlFe6eXev33Giv/uJiu3rN6R8ERERFqK3zTZuq+I3p3V/1BEJByE3DQXcuoGn5lC6WEP67bm8PpHu3n9o90ktYvknAw352S46dYxDoseziIi0oKycsooq/DQS/0PRUTCghLEVsRiMRhxfmdGnN+ZwtIqNu7IY8O2XN79LJOVn+wjPsbBgHQ356S3p1eXdtisqkAWEZHmtbV28DQNUCMiEh6UILZS7WKdXDygExcP6MThSg9f7Mxnw7Zc1nx5kA8/30+k00a/7omck+Hm7G4JRDj0oyAiIk1v695CkttFkhAXEexQRESkAZQVtAFREXYuOCuFC85Kodrj4+s9hWzYlsvGHXn87+tsbFYLZ3VtxzkZbvqntyc2yhHskEVEpBXw+f18k1nI+b2Tgx2KiIg0kBLENsZht9I/vT3909vj8/vZnlnMhu25fL4tly925mOshIxUF+dkuBmQ0Z728RpxTkRETs3eQ2VUVPnUvFREJIwoQTwFvoIsSvbvx2dLxNKuI4YjPOd0slos9OrSjl5d2nHVD9LZl13G+m01yeLfV2/n76u30zk5JjDITaf20RqBTkREGmzL3gIAenZWgigiEi6UIJ4Cz7aPydu0MrBsRLfD4uqIpV0nLAmdsLo61iSOzuggRtk4hmHQJSWWLimxjB/ajeyCw2zYnsuGbbks+2g3y46MiJpeOyJqJ42IKiIi323rviI6uaOJj1bXBRGRxnrrrRW8+upSnn32xRa9rhLEU+Ac9GNSLhpD3s5t+AoP4C/cj79wP54tH4KvOrCfEeWqSRrbdcLSriPW2tdwSByTE6K4fFAXLh/UhaKyKj7fXjsi6rpMVn66j/hoBwPS23NOhlsjooqIyHG8Pj/bM4sY2q9jsEMREZFGUIJ4CgzDgr1dCrYu0di6DAisN00/Zmke/sID+GqTRn/hATxbPwRvfYljTa1jqCeOrpi6I6Juqh0Rde1X2Xy48QCRTit9u9cki300IqqIiAC7DpRQ7fVr/kMREeAPf7iT9u3d3HjjTQAcPnyYK674IY8+upDXX/8nmzd/QWFhAampadxyyyz69u0ftFj1Sb4JGYYFIy4JS1wSti79A+trEsd8/IX7axPHmlpHz9Z/f2fiWJM8hlbiGBVhZ/BZKQw+KwWP18dXR0ZE3Z7HJ98aEbVfenviNCKqiEibtGVvIQbQs7Mr2KGISBvi2fZfPN/8p0nOZRgGpmmecLu951DsGRc26FwjRozk4Yfn8Otfz8AwDD766EO6du3Gv/71BgCLF7+CxWJl/vxH+MtfFvLnPz/TBHdwapQgtoCaxNGNJc79HYnjMU1VwyRxtNus9O/Rnv49akZE3ZFVXDvITV5gRNT02hFRz0lvj9sdG9R4RUSk5WzZW0jnlFiiI+zBDkVEJOjOO28QXq+XzZu/oG/f/rz77kpGjBjJJZdcSkREBFarjYMHDxAbG0tubm5QY1WCGETNkThaXCkYjmgMS8v2CbRaLPTs3I6enY+OiLphWy4btufyj9Xb+cfq7STEOWkX4yQxPoLEuAgS4yNof8x7NU0VEWkdKqu97DpQzKUD04Idioi0MfaMCxtcq3cyNpsFr9ffJOeyWq0MH34Zq1evonPnrnz++Xpmz76HnJwc5s+fy549u+nSpQuxsfGYZtNc81TpE3kIOmniWLQfX0Ft4lh04LjEEQCbA8MeCY4IDHskhiMSwx4B9oij72tfDUdkzfra/ersY3diGI1LNo8dEfVHQ7uRXXiYjdvzKCirJiu7lD0HS1n/TS4+f90q++gIWyB5bB8fecz7mgQyOsKmaTZERMLA1j0FeH2m5j8UETnGiBEj+e1vZ3DGGd0499zzaNcugRtu+BVjx47niScWYRgGb7/9Jrt27QhqnEoQw0idxLFz/8B60/RjltXUOPqLszGrKzA9lVBdcfS9pxJ/WR5mde16TwX4fQ27sD3imEQyEqM26axJJCPqJqJHEs8jyac9Erczgh8OSMad0o68/MMA+E2T4rJq8ksqyS+uJK+4gvySKvKLK8kurODrPYVUeerG57RbA8nikVrHY1/jYxyaekNEJARs2pGH1WKQnhof7FBEREJGenoGLlc7XnjhuWMGqyknMjICwzDYs2c3L7/8Al6vN6hxKkFsBQzDghHrxhLrbtRxps9TTyJZgVldeXS9pxKzugI8lZieo/uZh0tqlmv3owFV4WU10YLFAhYrNsNKisVKisUCFltgvRFvBZcVPxa8pkG1Dzx+qPYZVHlNKougMheqfVCOhVIMdpoWTMOC3WHH6bDjjHAQ4XQQEeEgKtJJVKSTyEgnFqsVLDV/jNpXjq0hPWFH5G+tP9F+TXx8aXYsnsN+DLuzplbY5sCwHXlf84rVrppVEQkpm7bncUaHOHUdEBH5lssuG8Xf/raIiy4aCsBtt93BggWP8uc/P47b7WbUqCt4+uk/U1xcFLQYDfO7huZpxfLzy/D7T/3W3e5YcnNLmzCi8GWaJvg8xyWS1CaXNUlmJdERBuVlNTWXpt9XU4Pp94HfX7NsHrvOV9P++thlv68mEfV7we/H7/Pi8/kwvV78x57P9GMxfVgwsRht4cfbCCSPNU2LnWBz1i47j66vs+ysk3QeTTidtUlo3WPDKQnV/83Gac3lZbEYJCbGBDuMsHO6z8eKKi+/mf8RIwd3YfzQbk0YWevVmv8fNheVWeO11jI7dGgvKSldmuXcTdkHMVhOVD7f9YzUV3ty2gzjmASFEzcnaueOxduCv5g8Xh8FxRXkFR+msOgwBcWHKSo5TFFJBcWlFZSVV9Ykk9T9j29SfyJ07HrDAKvVgtVSM0CPxWJgtViwWWteLVYDm8WC1WJgsda8Ht1uYLUaNccblqPvLTXbbFYLFqsFmwUSYh34KitwGF6cFh8OvDgMLza82PFgNb0YvmpMTxV4qzG91eCtOvpaWYrprcb0HrPdU8VxNZonYxh1k02LrWYdBjXF8q339a47Un7HrzPqbOdb+xrHrDPqbq9n3SGnnerqY5onH3uuOsvfOv6461LPNiOw+eg2o/awb2+rZ996k2yjnrf1xXSC4060/STXOpLw50c5qDr8rT7Mxx3bgC8HGvIFQmPOaxjYuw/G4ko5+XklpGzLLMLvV/9DEZFwpQRRWi27zUpyYgzJJ/h2xOf3U1RaTVF5FT6fidfnx+evfa1d9vpMvP5jl4/sY+Krs732fe12n8/E4/NT4fPj9Zv4qo/Z7jPx+f14fd6ac/qPnqvhDMABOLDbYnDarUQ4rDjtVpxHXo+si/zWst1ChM0kwuIn0urDYXiJsPhwWHzY8db+8YDPA56q45NObzX4vIB5tElsoCHC0XU1jRNOvP2k66CmxtisWW/WOZdZu8vx67xVFvxe3zH7cPz+9Rx/tPTrO3d9y9+x7dvrv31cPevM+pL2OseY9bxtSFNls87Ltxc83772caesL66TrTiVY45nRMTiUIIYdrbsLcRus9CjU1ywQxERkVOgBFHaLKvFUjPATXxEsEMBahKqI8mlz+/H4zOJiY3g4KESqjw+Kj0+qqp9VNW+Vlb7qK5vfe1rWYXn6HLtusZw2Cw4HZE47TE4HVYijkk+7TYLZiCPqk0Ia/8yOZIcHrmvo/cX2K92vXlM8nLkXCZ8Kwcz657n2P0COx09l8Nuw+fzYzFqmk9YDONbr0fXG4ZR0/X12H2OvD9mvWEY9Z/vyLpj1hsG9V+z9noYYDFqavAMOLqu9r1hHK3ds9QuYxx9bwRqLI/dXnON49Zx7LFHznnMNQ0Dd/sY8vPLv3W/dY8JBtM0w6ZZs9S1dW8hvbsmYLdZgx2KiIicAiWIIiHCMAxsVoOaz1Q1H6zcidFY/U3T9t1vmng8/lNKNmuWvVR5/JSUe/D4/LXJzdHY4VstTI/8Xafl6dFml0ePP5rw1NnvmHVG7YmOvDcsR85dt9kv1PQX8NfW5Hp8fvz+mns3/Sb+2iTcbxJY9psm/tp1fr+JaR6zn78mUfH7663fa/UMOJogW6hNlI9PlgNJsWFgHJOEG9SXgNeep3Y/45jE3DjmvFaLwSXnptKjk0bBDCdlFR725ZQx9JzUYIciIiKnSAmiSBthMYyaGkCHldbc8Ku5OuGbgWSSQFJZs47aZNIMJJN+82jCeXTfmlpOs7ZFrWl+e90xr3CCbcduP3J8fcc2fP+oaCelpZV14jw2aTbrXX98Qh1Ipk9wnm+XmcfnP5qkH0niv3XegpJKUIIYVuxWC2d1bcfQAak0ZHRrEZGmoFYn9TvVsUiVIIqINIBhGFgNA6vl5PuGk9Y6qp0Eh9Nh5ZZJA3C3j9bPlYi0CKvVhsdTjcPhDHYoIcfn82KxNL65fyv7qCMiIiIiIm1FTIyLoqJcqqurTrnGrDUyTT+lpYVERjZ+uifVIIqIiIiISFiKjIwGoLg4D5/P26Tntlgs+JtoLIiWZ+BwRBAT0/iuGkoQRUREREQkbEVGRgcSxabUVrthqImpiIiIiIiIAEoQRUREREREpJYSRBEREREREQHacB9Ei+X050ppinO0NSqzxlOZNZ7KrHFaa3m11vtqbk1Vbir/xlF5NZ7KrPFUZo3XWsvsu+7LMDUerIiIiIiIiKAmpiIiIiIiIlJLCaKIiIiIiIgAShBFRERERESklhJEERERERERAZQgioiIiIiISC0liCIiIiIiIgIoQRQREREREZFaShBFREREREQEUIIoIiIiIiIitZQgNtKKFSsYOXIkw4cPZ/HixcEOJywsXLiQUaNGMWrUKB566KFghxNWHnzwQWbNmhXsMMLC+++/z/jx47nsssu47777gh1OWFi+fHng/+aDDz4Y7HCkFdAzsvH0jDw1ej42nJ6PjdfWn49KEBshOzubefPm8fLLL7N8+XKWLFnCjh07gh1WSFuzZg0ff/wxr7/+OsuWLeOrr77i3XffDXZYYWHt2rW8/vrrwQ4jLGRmZnL33Xfz5z//mRUrVvD111/z73//O9hhhbSKigruv/9+XnzxRZYvX866detYs2ZNsMOSMKZnZOPpGXlq9HxsOD0fG0/PRyWIjbJmzRoGDx6My+UiKiqKESNGsHLlymCHFdLcbjezZs3C4XBgt9vp3r07Bw4cCHZYIa+oqIh58+Zx/fXXBzuUsPDuu+8ycuRIUlJSsNvtzJs3j379+gU7rJDm8/nw+/1UVFTg9Xrxer04nc5ghyVhTM/IxtMzsvH0fGwcPR8bT89HJYiNkpOTg9vtDiwnJSWRnZ0dxIhCX3p6Ov379wdgz549vPXWWwwbNiy4QYWB3//+98ycOZO4uLhghxIW9u7di8/n45e//CVXXHEFL7/8MvHx8cEOK6TFxMRw0003cfnllzN06FA6derEOeecE+ywJIzpGdl4ekY2np6PjaPnY+Pp+agEsVFM0zxunWEYQYgk/Gzfvp1f/OIX3H777XTt2jXY4YS0V155hQ4dOnDBBRcEO5Sw4fP5WLt2LQ8//DBLly5l8+bNan50Elu3buXVV1/lgw8+4OOPP8ZisfDss88GOywJY3pGnjo9IxtGz8fG0/Ox8fR8VILYKMnJyeTl5QWWc3JySEpKCmJE4WH9+vX8/Oc/55ZbbuFHP/pRsMMJeW+99Rb//e9/GTt2LAsWLOD9999nzpw5wQ4rpLVv354LLriAhIQEIiIi+MEPfsCmTZuCHVZI+/jjj7ngggtITEzE4XAwfvx4Pv3002CHJWFMz8hTo2dkw+n52Hh6Pjaeno9KEBtlyJAhrF27loKCAioqKli1ahVDhw4Ndlgh7eDBg9x4443MnTuXUaNGBTucsPDcc8/x5ptvsnz5cmbMmMEll1zCHXfcEeywQtrFF1/Mxx9/TElJCT6fj48++oizzjor2GGFtF69erFmzRoOHz6MaZq8//779OnTJ9hhSRjTM7Lx9IxsHD0fG0/Px8bT8xFswQ4gnCQnJzNz5kymTJmCx+Nh4sSJ9O3bN9hhhbRnn32Wqqoq/vSnPwXWTZo0iauuuiqIUUlr069fP371q18xefJkPB4PF154IRMmTAh2WCHtoosu4uuvv2b8+PHY7Xb69OnDddddF+ywJIzpGdl4ekZKc9PzsfH0fATDrK/TgIiIiIiIiLQ5amIqIiIiIiIigBJEERERERERqaUEUURERERERAAliCIiIiIiIlJLCaKIiIiIiIgAShBF5DtkZWXRs2dPysvLgx2KiIhIyNDzUVozJYgiIiIiIiICKEEUCbqsrCwGDhzI008/zYUXXsgFF1zAnDlzTrj/Z599xoQJExg4cCBXXnklmzZtCmzr2bMnTz/9NEOGDGHQoEE8+uij+P1+APLy8rjlllsYNGgQw4YN46GHHqK6uhqAqqoq7rvvPgYPHsygQYP43e9+R1VVVeC8zz//PD/4wQ8499xz60zovGLFCn74wx9y3nnnMWHCBD7++OOmLh4REWmj9HwUCQ4liCIhoLS0lKysLD744AOefPJJXn75ZT7//PPj9jtw4ADTpk3jhhtu4H//+x+/+MUvmDp1KkVFRYF9PvzwQ958801eeeUV3nzzTZYsWQLA9OnTAVi9ejVLly7l008/ZcGCBQA8/vjjbNy4keXLl7N69Wr279/PE088EThnTk4Ob7/9Ni+99BIvvfQS69evp6Kigt/97nc8+uijfPbZZ0yePJm77roL0zSbsaRERKQt0fNRpOUpQRQJEVOnTsXhcNC/f3+6devG3r17j9vnzTffZNCgQVx66aXYbDYuv/xyMjIyeOeddwL73HLLLSQkJNC5c2emTJnCv/71L/bt28fnn3/O7NmziYmJITk5mZtuuonXX38dgH/9619cf/31JCcnExMTw0MPPcTEiRMD55w2bRoOh4PevXtzxhlnkJWVBYDT6WTp0qV8/vnnjB07lvfffx/DMJq5pEREpC3R81GkZSlBFAkRCQkJgfc2my3Q9OVYBw4c4KOPPmLgwIGBP5s3b+bgwYOBfbp06RJ4n5KSQm5uLvn5+URFRdW5RseOHcnLy8Pj8ZCXl0dKSkqd4zp37hxYjouLC7y32+34fD4iIyN54YUXKCgo4Fe/+hUXXnghixYtOv2CEBEROYaejyItyxbsAESk4dxuNyNHjuShhx4KrMvMzKRdu3aB5ZycHNq3bw/UPDA7dOhAx44dOXz4MAUFBYGHYFZWFi6XC7vdTnJyMtnZ2Zx99tkAbN68mY0bN3LxxRefMJaysjLKy8tZuHAhXq+XNWvWcOONN3L++efTv3//Zrh7ERGR+un5KNJ0VIMoEkZGjRrFBx98wNq1azFNk/Xr13PFFVewefPmwD4LFiygrKyM3bt38+KLLzJu3DiSk5O54IILuP/++ykvLyc7O5sFCxYwZswYAMaMGcPTTz9NXl4epaWlPPLII+Tl5X1nLIcPH+ZXv/oVH330ETabjaSkJAzDID4+vlnLQERE5Nv0fBRpOqpBFAkjXbt25bHHHuPhhx9mz549JCQk8Lvf/Y4LLrggsE9qaiqjRo3C5/NxzTXXMG7cOADmzp3L/fffzw9+8AMArrjiCm655RYAbrjhBioqKhg3bhxer5fLLruMG2+8kZycnBPGkpSUxEMPPcScOXM4dOgQ7dq14/e//z1nnHFG8xWAiIhIPfR8FGk6hqkhlURajZ49e7JixQoyMjKCHYqIiEjI0PNRpOHUxFREREREREQAJYgiIiIiIiJSS01MRUREREREBFANooiIiIiIiNRSgigiIiIiIiKAEkQRERERERGppQRRREREREREALAFO4BgKSwsx+8/9fF5EhNjyM8va8KIWj+VWeOpzBpPZdY4rbm8LBaDdu2igx2GiIhIWGmzCaLfb55WgnjkHNI4KrPGU5k1nsqscVReIiIicoSamIqIiIiIiAigBFFERERERERqtUiCuGLFCkaOHMnw4cNZvHjxcdu3bNnChAkTGDFiBLNnz8br9QKwbt06xo8fz5gxY7j++uspLi4GoKSkhOuuu47LL7+cq6++mtzc3Ja4DRERERERkVbNME2zWTufZGdnc9VVV/Haa6/hcDiYNGkSjz76KD169AjsM3r0aO677z769+/PHXfcwdlnn83kyZMZPnw4Tz75JD169GDu3LlYLBb+7//+j3vvvZeUlBSuu+46li1bxocffshjjz3WqLjy88tOq9+N2x1Lbm7pKR/fFqnMGk9l1ngNLTPTNCkszKW6uhJou33wLBYLfr8/2GGcMqvVRkyMi8jI4wejsVgMEhNjghCViIhI+Gr2QWrWrFnD4MGDcblcAIwYMYKVK1cyffp0APbv309lZSX9+/cHYPz48SxYsIDJkyfz1ltvYbfb8Xg8ZGdn07NnTwA+/PDDQE3k6NGjuffee/F4PNjt9ua+HQB8fj8H88opKDzcItdrLRISNJqghI6ysmIMwyA5ORXDaLut7W02C15veCaIpmni8VRTVFTTiqS+JFFEREQap9kTxJycHNxud2A5KSmJTZs2nXC72+0mOzsbALvdzjfffMO1116LzWbj//7v/447xmazERMTQ0FBAcnJyc19OwAsXrWNDzceaJFrtSajLzyD8d87I9hhiABQUVFGQkJym04Ow51hGDgcTlwuN8XFeUoQRUREmkCzJ4j1tWA1DKPB23v27MmaNWv4xz/+wcyZM/nHP/5R73UslsZ9yDudZkdTRp/NgN4pp3x8W/TWmt18vi2HaeP7BjuUsON2xwY7hLDTkDLLyTFxOh11ft+0VTZbeCfJVmsERUV+/V8RERFpAs2eICYnJ7Nu3brAck5ODklJSXW25+XlBZZzc3NJSkqiqqqKjz76iEsvvRSAK664ggcffBCoqYXMy8sjJSUFr9dLWVlZoAlrQ51uH8RLBqapb1gjZB1K4JUPdrJjTz7x0Y5ghxM21Aex8RpaZn6/H5/PpC33P4TwbmJ6LL/ff9y/u/ogioiINF6zf208ZMgQ1q5dS0FBARUVFaxatYqhQ4cGtnfq1Amn08n69esBWLZsGUOHDsVms/GHP/yBL7/8EoC3336bc845B4Bhw4axbNkyAN566y0GDhzYYv0P5dRkpLoA2J5ZFNQ4RERERETkxFqkBnHmzJlMmTIFj8fDxIkT6du3L1OnTmXGjBn06dOHuXPncuedd1JeXs6ZZ57JlClTsFqtzJs3j9///vf4fD6Sk5O5//77AbjpppuYNWsWo0aNIjY2lrlz5zb3bchp6pISi8NuZVtWEQN7JZ38ABFpkFtumcHQod9n7Njxx21buPAxiouLmD37npYPTERERMJSs09zEao0zUXLm/fKJkrKqrj72vOCHUrY0M9Z4zW0zA4d2ktKSpcWiCh4GpIgtpYmpvX9e6qJqYiISOOF98gEElbO7JbAvpxSKqq8wQ5FJCz84hdXs2rVSgAqKir4/vcHs2zZPwHweDz88IfDmDBhNK++ugSAgwcPcNNNNzB8+Pe44YZfkJOTXed8r7/+TyZN+hEjR/6A3/3ut+Tn5yEiIiJyrGZvYipyxFlnJGKasPNAMWefkRjscETq+O/mg3y86WCLXOuivh24sE+Hk+53wQUXsW7dJ/zwh5fxxRefY7Va+fzz9YwbN5FNmzaSnJxMfLwrsP9dd83irLPO5uGH5/PNN1v4v//7Dd///iUAvP/+e7z44nPMnbuATp1SefrpP3P33Xfwl78801y3KSIiImFINYjSYnp1TcBiGGzLLA52KCJh4YILLmL9+s8A2LDhM0aPHsvGjRsAWLv2vwwZ8r3Avvv3Z7F169dcd92vcTgc9OnTj0sv/WFg+5tvLucnP5lMt27dcTqdXH/9dL7++kv27dvbsjclIiIiIU01iNJiIp02OifHaCRTCUkX9mlYrV5LOvPMs6iqqmLfvr2sW/cZd9xxNx9++D579+7hf/9bw2233cFXX20GoKAgn8jIKKKjj/a5S0npQFZWJgA5OYdYtOhJnntu0TFXMDh48CAdO6a15G2JiIhICFOCKC0qPdXFhxv34/X5sVlVgS3yXSwWC4MHD+HDD1eTm5tD9+49OOecgbz99psUFRVw9tl9A/u2b++mouIwxcVFgWanubm5ge2Jie2ZNOmnjB49NrBuz57ddOnSucXuR0REREKfPqFLi8pIi8fj9bPnkEbmFGmIIUO+x5Ili+nXrz+GYXDuuQP55z//waBBQ7BYjv4K79ChI3379mfhwseoqqpky5avePfdtwPbL7tsFP/4x2KysjLx+/3885//YNq0n1NRURGM2xIREZEQpRpEaVHpqS4AtmcW0aNTfHCDEQkD558/mPLycgYMOBeAc845j8rKyjr9D4+4994/8ac/3cvo0cPp2DGVoUMvDmy77LJRlJaW8NvfzqCgoIAuXbrw0EPziYuLaxXTXIiIiEjT0DyIp0jz0zXekTK74+n/kdwukpuu7BfskEKefs4aT/MgNo7mQRQREZFjqYmptLj01Hh27C/G3za/mxARERERCVlKEKXFZaS5KK/0ciCvPNihiIiIiIjIMZQgSotLT3MBaLoLEREREZEQowRRWpw7PgJXjINtWcXBDkVERERERI6hBFFanGEYpKe62J5VFOxQRERERETkGEoQJSgy0lwUlFSRV6w52EREREREQoUSRAmK9NSaORC3Z6qZqYiIiIhIqFCCKEGR6o4h0mljm5qZioiIiIiEDCWIEhQWi0F6ajzbNJKpSMjxer3k5GQHOwwREREJAiWIEjTpqfEczD9M6eHqYIciElZ++cuf8dZbK5rt/PfccwcfffRhg/a96KKB7Nq1o9HXePbZp7jzztsafZyIiIg0LyWIEjTpqS4Admi6C5GQUlRUFOwQREREJEhswQ5A2q4zOsRhs1rYllXEgAx3sMMRCVmfffYJ8+c/Qnb2QS6++FI8nppa96qqSp588nE+/PB9TNNk+PDLmDbtRux2OwCvv/5PlixZTElJCf36DeC3v51FYmJ7NmxYx6OPPkT//uewatVbxMe3Y9q0X3PppSOYP/8RNm3ayFdfbebAgQP85jczeeWVf7BixetkZx/C4XAybtwEfvnLaYH43n33Hd59dybl5eVMmPBjrr12KlarlenTr+Pii3/AhAk/AeDVV5fwwQerWbjw6Tr3V1VVyeOPP8Znn/2P/Pw82rd38+tf38TQod9nw4Z1PPLIn+jQoSNfffUl99//EOecM7CFSl5ERKTtUYIoQWO3WejWIZZtGslUQoBn23/xfPOfFrmWvedQ7BkXNmjfgoJ87rjjVm677Q4uvvhSli9/LdC8dOHC+WRl7eP55/+O329y112388ILf+WXv5zG+++/x4svPsfcuQvo1CmVp5/+M3fffUcgOduzZxfnnTeIlSvfZ926dcya9X9069aDm266he3bvwkkdl988TkvvPBX/vznZ0hL68wXX3zO9OnXMWLESFJT0wD48stN/PWvL1FaWsrNN99IUlIyV1zxowaXx9///hJ79+7m2WdfIjIyksWLn+exxx5m6NDvA7B37x4mT57Cffc9hM2mx5aIiEhzapEmpitWrGDkyJEMHz6cxYsXH7d9y5YtTJgwgREjRjB79my8Xi8A69evZ8KECYwdO5ZrrrmG/fv3A/DZZ58xaNAgxo4dy9ixY/nd737XErchzSA9zcW+7FKqqn3BDkUkJK1Z8zFpaWkMH34ZNpuNCRN+TGpqGqZp8tZbb3DDDb8hPt5Fu3bt+OUvp/HGG68D8Oaby/nJTybTrVt3nE4n118/na+//pJ9+/YCEBkZxfXXT8fhcHD++YMZNOgCPvjgveOu37Nnb5599kXS0jpTUJCPx+PB6XSSl5cb2GfatBuJi4unU6dUrrzyJ6xevapR9zh+/JXcd9+DREZGkpOTTVRUFLm5OYHtFouF4cMvIyIiQgmiiIhIM2v2J212djbz5s3jtddew+FwMGnSJAYNGkSPHj0C+9x6663cd9999O/fnzvuuIOlS5cyefJkbr31Vv785z/Tq1cv/vnPf3Lffffx5JNPsnnzZn7xi18wbdq077iyhIP0VBf/WruXXQeK6d01IdjhSBtmz7iwwbV6LamgIJ/27ZPqrEtJ6UBRUSFVVVX85jfTMAwDANM08Xi8VFVVkZNziEWLnuS55xYdc6RBdvZBrFYbSUlJOJ3OwBa3O4n8/Lzjrm8YBn/72zP8+9/v065dAj179gbA7/fXiedk5/kuZWVlPPLIg3z99Zd06pRKx46dME0zsD0mJhaHw9Goc4qIiMipafYEcc2aNQwePBiXywXAiBEjWLlyJdOnTwdg//79VFZW0r9/fwDGjx/PggULmDhxIjfddBO9evUCoGfPnrz00ksAbN68mfz8fN5++21SUlK4++676dChw3HXltDXo1M8BrAtSwmiSH3at3eTnX2wzrq8vFzi4+Ox2+389a+L6dQpFYCKigoKCvJxOp0kJrZn0qSfMnr02MBxe/bsplOnVDZv/oKCggJ8Ph82W01DkkOHDnHmmWcdd/0lSxaze/dOlixZTkxMDF6vl/fff7fOPvn5+bRv7w6cJzm55vex1WrF4/EE9isurr85+cMPz6Fr1248+OCj2Gw2Nm7cUOcatfmviIiItIBmb2Kak5OD2310AJKkpCSys7NPuN3tdpOdnY3D4WDs2JoPNn6/n4ULF3LppZcCEBsby5QpU1i2bBnDhg1j5syZzX0b0kyiImykJcVoPkSRExgy5HtkZ2ezbNmreL1eVqxYxp49u7FYrAwffhl/+ctCSktLqaio4OGH53D//fcAcNllo/jHPxaTlZWJ3+/nn//8B9Om/ZyKigoASktLeOmlv+H1eli79mM2bPiMSy8dAYDD4aC8vByA8vJybDY7druNw4cPs3DhY3g8Hnw+byDGZ555ktLSUvbt28Mrr/ydUaOuACAtrTOffLKWqqoq9u/PYtWqt+u9x/LycpxOJ1arlezsQzzzzF8AAt0NREREpOU0ew3isc2EjjCO+Tr4ZNurq6uZNWsWXq830KT03nvvDWy/6qqreOSRRygtLSU2NrbBcSUmxjR43xNxuxt+PalRX5n1TXfz3mf7aJcQjc2qmVe+TT9njdeQMsvJsQRqz0JZ+/YJPPLIfObO/RMLF87jvPMG0a9ffywWg1tuuY0nnljAlCk/prKykn79BnD//Q9is1kYPXoM5eWl/Pa3MygoKKBr16488sgCEhJcWK0WYmNjycvLZeTIH5KQkMCcOQ/RtWsXAEaMuJxHHnmQ7OyDTJt2I3ffPZsxY35IZGQU3/veUPr27c++fXu54IIhAJx55plcddWPcDicTJp0NT/84Q8BuOaaa7nvvnu44ooRdOqUysiRY/jss0+w2SxYLAaGYWCzWZg58xb+9Kf7ee21pbhc7fjRjybwzTdbyMzcg9VqAYyT/ltZLBb9XxEREWkChllfhtaEXn/9ddatW8f9998PwBNPPIFpmnWamP785z/n3XdrmhOtW7eOBQsW8MILL1BeXs4NN9yAy+Vi7ty5OBwO/H4/Tz31FNdddx1WqxWAgQMH8tFHHxEZGdnguPLzy/D7T/3W3e5YcnNLT/n4tuhEZfbplmz+svwr7rpmIGd0iAtCZKFLP2eN19AyO3RoLykpXVogotCzYcM67rrrdv71r9XYbBa8Xv/JDwpx9f17WixGk3wZKCIi0pY0+9fnQ4YMYe3atRQUFFBRUcGqVasYOnRoYHunTp1wOp2sX78egGXLlgW233rrrXTp0oX58+cHBiiwWCy8++67vPPOO4H9+/Xr16jkUEJLRpoLQM1MRURERESCrNmbmCYnJzNz5kymTJmCx+Nh4sSJ9O3bl6lTpzJjxgz69OnD3LlzufPOOykvL+fMM89kypQpfP3116xevZoePXowbtw4oKb/4qJFi3jwwQe56667eOKJJ0hISOChhx5q7tuQZuSKcZLkimRbZhEjzu8c7HBERERERNqsZm9iGqrUxLTlfVeZPfuvr/liRz7zZ1xUpw9qW6efs8ZTE9PGURNTEREROVboj9AgbUJ6qouyCg+HCg4HOxQRERERkTZLCaKEBPVDlGBoow0oWh39O4qIiDQdJYgSEpLbRRIXZWdbZv0TaYs0NYvFWmcuPwlfHk81Vmuzd6kXERFpE5QgSkgwDIP0NBfbs4qCHYq0EZGRMZSWFmGa4d//rq0yTZPq6iqKinKJiXEFOxwREZFWQV+5SshIT3Wx/ptcCkoqSYiLCHY40srFxMRTWJhLdnYW0HabKFosFvz+8E2SrVYbsbHtiIyMDnYoIiIirYISRAkZGWnxAGzPKmbQmUoQpXkZhkFCQlKwwwg6jZQrIiIix1ITUwkZaUkxOB1WtqmZqYiIiIhIUChBlJBhtVjo0Sme7RrJVEREREQkKJQgSkhJT41nf2455ZWeYIciIiIiItLmKEGUkJKR6sIEdmRpugsRERERkZamBFFCSreOcVgthvohioiIiIgEgRJECSkOu5WuHWLZnqkaRBERERGRlqYEUUJORqqL3QdLqPb4gh2KiIiIiEibogRRQk56qguf32T3wZJghyIiIiIi0qYoQZSQ0yM1HoBtGqhGRERERKRFKUGUkBMTaaeTO1rzIYqIiIiItDAliBKSMlJd7NhfjN9vBjsUEREREZE2QwmihKT01Hgqq31k5pQFOxQRERERkTZDCaKEpIw0F4DmQxQRERERaUFKECUkJcRFkBgXoX6IIiIiIiItqFEJYnV1NXv37sU0Tfx+f3PFJAJARlo827KKMU31QxQRERERaQkNShDLy8uZNWsW/fv3Z+zYsezZs4cRI0awa9euBl1kxYoVjBw5kuHDh7N48eLjtm/ZsoUJEyYwYsQIZs+ejdfrBWD9+vVMmDCBsWPHcs0117B//34ASkpKuO6667j88su5+uqryc3Nbej9ShhJT3VRUl5NTlFFsEMREREREWkTGpQgzpkzB4/Hw7vvvovdbqdz58788Ic/5A9/+MNJj83OzmbevHm8/PLLLF++nCVLlrBjx446+9x6663cddddvPPOO5imydKlSwPr77//fpYvX86YMWO47777AHjssccYOHAgb7/9NldeeSX3339/Y+9bwkD6kX6IamYqIiIiItIiGpQgfvjhh/zxj3+kU6dOGIaB1Wrl5ptv5uuvvz7psWvWrGHw4MG4XC6ioqIYMWIEK1euDGzfv38/lZWV9O/fH4Dx48ezcuVKqquruemmm+jVqxcAPXv25ODBg4F4xowZA8Do0aP5z3/+g8fjadSNS+jrmBhFTKSd7ZnFwQ5FRERERKRNaFCC6HQ6KS0trbOuqKiI2NjYkx6bk5OD2+0OLCclJZGdnX3C7W63m+zsbBwOB2PHjgXA7/ezcOFCLr300uOOsdlsxMTEUFBQ0JBbkTBiGAbpqfEayVREREREpIXYGrLT+PHjuf7667nxxhvx+Xx88sknLFy4kCuuuOKkx9Y3wIhhGA3eXl1dzaxZs/B6vUybNu2E17FYGjcga2JiTKP2r4/bffIEWepqbJkN6JXM5yu+wua00y4uopmiCm36OWs8lVnjqLxERETkiAYliL/+9a+JiIjgkUcewefzcddddzF27Fiuv/76kx6bnJzMunXrAss5OTkkJSXV2Z6XlxdYzs3NDWwvLy/nhhtuwOVy8eSTT2K324GaWsi8vDxSUlLwer2UlZXhcrkadMNH5OeX4fef+uiYbncsubmlJ99RAk6lzDq0q0kK//fFfgb2SjrJ3q2Pfs4aT2XWOK25vCwWo0m+DBQREWlLGlTttm3bNn71q1/x9ttvs3HjRlatWsWNN97I+vXrT3rskCFDWLt2LQUFBVRUVLBq1SqGDh0a2N6pUyecTmfgXMuWLQtsv/XWW+nSpQvz58/H4XAEjhk2bBjLli0D4K233mLgwIGB5FFaly7JsTjsFg1UIyIiIiLSAk5Yg+j3+6mqqsI0TSZPnsyaNWsCzUENw6C0tJRp06bx+eeff+cFkpOTmTlzJlOmTMHj8TBx4kT69u3L1KlTmTFjBn369GHu3LnceeedlJeXc+aZZzJlyhS+/vprVq9eTY8ePRg3bhxQU3O4aNEibrrpJmbNmsWoUaOIjY1l7ty5TVciElJsVgvdO6ofooiIiIhISzDME8xCnp2dzWWXXUZlZSWmadbpF3jE0KFDeeqpp5o9yOagJqYt71TLbNlHu1ixZg8Lbx5KpLNBraJbDf2cNZ7KrHFac3mpiamIiEjjnfDTdnJyMu+99x4VFRVMmDCB1157rU6i6HA46ow+KtJc0tNcmCbs3F/M2d0Sgx2OiIiIiEir9Z3VMYmJNR/GP/nkk3q3FxcXEx8f3/RRiRyje8c4LIbBtqwiJYgiIiIiIs2oQe31Pv/8cx555BGys7Px+/0AeL1eCgoK2Lx5c7MGKBLhsNElJYZtmcXBDkVEREREpFVr0Cim99xzD+np6YwcOZL09HR+85vfEBcXx8yZM5s7PhEA0lNd7DpQgsfrD3YoIiIiIiKtVoMSxL179zJ79mzGjx9PSUkJ48aN47HHHuPVV19t7vhEgJoE0evzs/dQ6xxMQ0REREQkFDQoQUxISMDv99OpUyd27doFQPfu3cnOzm7W4ESOSE+r6euq6S5ERERERJpPgxLEAQMGcOedd1JZWUn37t3529/+xpIlS2jXrl1zxycCQFyUgw6JUWzLLAp2KCIiIiIirVaDEsS77roLu91OVVUVs2fP5u9//zuPP/44d9xxR3PHJxKQnupiR1Yx/vqn7hQRERERkdPUoFFMly5dyh133EF0dDSJiYm88847zR2XyHEy0uL5zxcHOJBbTmqSJr8WEREREWlqDapBfOaZZ4iIiGjuWES+U3qqC1A/RBERERGR5tKgGsTRo0dz9913M2rUKNq3b49hGIFtPXr0aLbgRI7VPj6CdrFOtmUWcck5qcEOR0RERESk1WlQgvjyyy8D8M9//rPOesMw2LJlS9NHJVIPwzBIT41ne1YxpmnW+aJCREREREROX4MSxK1btzZ3HCINkpHm4tMtOeQVV+J2RQY7HBERERGRVqVBfRBFQsWRfojb1Q9RRERERKTJKUGUsNLJHU2U08a2zOJghyIiIiIi0uooQZSwYjEMeqTGqwZRRERERKQZKEGUsJOR5uJg/mFKDlcHOxQRERERkValQYPU/O53v6t3vd1up127dnzve99j4MCBTRqYyImkp8YDsCOrmHMy3EGORkRERESk9WhQDaLNZuPNN9+kurqa9u3b4/V6eeutt8jOzmbfvn1MmzaNV155pbljFQGga0ocNquFbZlFwQ5FRERERKRVaVAN4r59+3jqqacYMmRIYN2Pf/xjnnzySebNm8emTZu49dZbufLKK5stUJEj7DYL3TrGqR+iiIiIiEgTa1AN4ldffcX5559fZ92AAQPYuHEjAH379iUvL6/JgxM5kYy0ePYeKqOy2hvsUEREREREWo0GJYjp6ek89dRTmKYJgGmaPP3003Tr1g2Af//736Smpp7w+BUrVjBy5EiGDx/O4sWLj9u+ZcsWJkyYwIgRI5g9ezZeb90P/fPnz+fxxx8PLH/22WcMGjSIsWPHMnbs2BP2kZTWKyPVhd802XWgJNihiIiIiIi0Gg1qYnrfffdxww038OKLL5KUlEROTg4JCQnMmzePdevW8X//938sXLiw3mOzs7OZN28er732Gg6Hg0mTJjFo0CB69OgR2OfWW2/lvvvuo3///txxxx0sXbqUyZMnU1paygMPPMC//vUvfvWrXwX237x5M7/4xS+YNm3aad6+hKvuneIxDNiWWcSZXROCHY6IiIiISKvQoASxe/fuvPXWW2zcuJGcnBxSUlLo378/FouFyspK/ve//2G32+s9ds2aNQwePBiXywXAiBEjWLlyJdOnTwdg//79VFZW0r9/fwDGjx/PggULmDx5MqtXr6Zr165ce+21dc65efNm8vPzefvtt0lJSeHuu++mQ4cOp1gEEo4inTbSkmLYnlUc7FBERERERFqNBs+D+NVXX7F//36qq6vZt28fb7zxBsuWLSMiIuKEySFATk4ObvfRqQiSkpLIzs4+4Xa32x3YPm7cOK677jqsVmudc8bGxjJlyhSWLVvGsGHDmDlzZkNvQ1qRjFQXOw8U4/X5gx2KiIiIiEir0KAaxAceeICXX36Zbt26YbMdPcQwDMaNG/edxx7pt3gswzAavL0+9957b+D9VVddxSOPPEJpaSmxsbHfedyxEhNjGrzvibjdDb+e1GjKMht4VgfeW59FSZWPnl3im+y8oUY/Z42nMmsclZeIiIgc0aAE8c033+Sll16iX79+jb5AcnIy69atCyzn5OSQlJRUZ/uxI6Dm5ubW2f5tfr+fp5566riaxWMT14bIzy/D7z8+OW0otzuW3NzSUz6+LWrqMkuOcwDw6eaDJESduBY7nOnnrPFUZo3TmsvLYjGa5MtAERGRtqRBTUwNw+DMM888pQsMGTKEtWvXUlBQQEVFBatWrWLo0KGB7Z06dcLpdLJ+/XoAli1bVmf7cQFbLLz77ru88847gf379etHZGTkKcUn4Ss+xklSu0jNhygiIiIi0kQalCBec8013H///Rw4cICKioo6f04mOTmZmTNnMmXKFMaNG8fo0aPp27cvU6dOZfPmzQDMnTuXBx54gMsvv5yKigqmTJnyned88MEHeeGFFxg1ahSvvvoq9913X0NuQ1qhjFQX27OK8dfTVFlERERERBrHMOvrBPgt5513HqWlpcf1HTQMgy1btjRrgM1FTUxbXnOU2UebDvDcW1v5468G0al9dJOeOxTo56zxVGaN05rLS01MRUREGq9BHfeWLVvWzGGInJqMVBcA27OKWmWCKCIiIiLSkr6ziemuXbsAjmtW2pgmpiLNKaldJHHRDrZnFgU7FBERERGRsPedNYgTJ05kw4YNjB49ut7t4dzEVFoHwzDISI1nW2ZxsEMREREREQl735kgbtiwAYCtW7e2SDAipyI9zcW6b3IpKKkkIS4i2OGIiIiIiIStBk8emJ2dTWZmZp2J7Q3DYODAgc0SmEhDHemHuC2riMFnpgQ3GBERERGRMNagBPGZZ57h0UcfJSoqqs6E9IZhsHbt2mYLTqQh0pJiiHBY2Z5ZrARRREREROQ0NChBfOmll1iwYAGXXnppc8cj0mgWi0GPTvFsyyoKdigiIiIiImHtO0cxPaKiooJLLrmkuWMROWXpaS7255ZTVuEJdigiIiIiImGrQQnij370IxYtWoTP52vueEROSUZqPAA79ms0UxERERGRU9WgJqZr1qxh27ZtPP7448TGxtbZpj6IEgrO6BCH1WKwPbOI/j3aBzscEREREZGw1KAE8Y477sBiaVBlo0hQOOxWzugQp36IIiIiIiKnoUEJ4gMPPMDixYuJiYlp7nhETll6WjyrPs2k2uPDYbcGOxwRERERkbDToGrB0tJSKisrmzsWkdOSkerC5zfZdaAk2KGIiIiIiISlBtUg9u/fnx/96EcMHjyY9u3bYxhGYNttt93WbMGJNEaP1HgMYHtWEb26tAt2OCIiIiIiYadBCaLT6eSiiy4CoKioqDnjETll0RF2Ormj2ZalkUxFRERERE5Fg/sgioSD9DQXa748hM/vx6qBlUREREREGqVBCWJBQQEvvfQS2dnZ+P1+ALxeLzt37uS1115r1gBFGiMj1cUHG/aTmVNG15S4YIcjIiIiIhJWGlTFcuutt/Lxxx+Tl5fHzp07MQyD1atXM3jw4OaOT6RR0lPjAdieqWamIiIiIiKN1aAEccOGDSxatIiZM2cSFxfHnDlzmDdvHhs3bmzm8EQaJyEugvbxEZoPUURERETkFDQoQYyOjiY+Pp4uXbqwbds2AIYNG8bOnTubNTiRU5Ge6mJ7ZhGmaQY7FBERERGRsNKgBDE9PZ3FixcTERFBVFQUmzdvZvv27Vg0CIiEoIy0eEoOe8gurAh2KCIiIiIiYaXBfRCff/55srKymD59OldddRU/+tGP+NnPftagi6xYsYKRI0cyfPhwFi9efNz2LVu2MGHCBEaMGMHs2bPxer11ts+fP5/HH388sFxSUsJ1113H5ZdfztVXX01ubm6D4pC2ISPNBcD2zKKgxiEiIiIiEm4alCCeeeaZrFq1irS0NEaPHs3q1at54403+PWvf33SY7Ozs5k3bx4vv/wyy5cvZ8mSJezYsaPOPrfeeit33XUX77zzDqZpsnTpUgBKS0u54447+Otf/1pn/8cee4yBAwfy9ttvc+WVV3L//fc39H6lDUhJiCIm0q5+iCIiIiIijdSgaS4A9u7dy2uvvUZOTg6zZs3i448/plu3bic9bs2aNQwePBiXywXAiBEjWLlyJdOnTwdg//79VFZW0r9/fwDGjx/PggULmDx5MqtXr6Zr165ce+21dc754YcfBmoiR48ezb333ovH48Futzf0dk6L6a2icv9BfEWHW+R6rUVldVSLldkFyYfJzczHl+Nskes1C8OK2f6sYEchIiIiIm1IgxLEf//739x2221ccsklvPPOO9x8883Mnz+fvLw8pk2b9p3H5uTk4Ha7A8tJSUls2rTphNvdbjfZ2dkAjBs3DqBO89JvH2Oz2YiJiaGgoIDk5OSG3M5pq/rvSxz45qMWuVZr0pLp9GgACxxetqwFr9r0cndejDH4mmCHISIiIiJtRIMSxEceeYSFCxdy3nnn8d5775GcnMxzzz3HL3/5y5MmiPWNJGkYRoO3N1RjB8xJTIxp9DWO8I36JVX9h57y8dL89ueWsWj5l0y8JJ2zuyUGO5xTcnjHekrWrySp+wBizrww2OGEFbc7NtghhBWVl4iIiBzRoATx4MGDDBw4EDiavJ1xxhmUl5ef9Njk5GTWrVsXWM7JySEpKanO9ry8vMBybm5une31SUpKIi8vj5SUFLxeL2VlZYEmrA2Vn1+G33/q0yC4e5xDbm7pKR/fFrndsS1WZjExfnZSzJq8BM4YkN4i12xq5oAzcB7cSc6/nqQ8shOWmPBMdFtaS/6ctQatubwsFuO0vgwUERFpixpU7darVy+WLFlSZ93bb79Nz549T3rskCFDWLt2LQUFBVRUVLBq1SqGDj1a+9apUyecTifr168HYNmyZXW212fYsGEsq206+NZbbzFw4MAW638o4cFmtdC9Y3xYj2RqWGwkjbsZTJPKD57G9PuDHZKIiIiItHINShDvvPNOFi5cyLhx4zh8+DA/+9nPmDNnDrNnzz7pscnJycycOZMpU6Ywbtw4Ro8eTd++ffn/9u48Oqo6T//4U5VakpCQEKiEkLAqQZQlSGRtg4DKEgUacEaxB/3RRPDg0WZoT4Pr0UEQRPDQoq0OvbgwAx4aMiDN0gQYkCgQQaKgYiuYzYQkhJC9qlK/P4AaadkKUrmVyvt1Th2q7r1167mfUwl8uN97v+np6crJyZEkLVmyRAsXLtSYMWNUU1OjqVOnXnafTzzxhA4dOqS0tDStWrVKzz333NUcBlqYpI7Ryi2uVHWt68obByhrm/YKHfKg3IVfq/7zTUbHAQAAQJAzeS52EeBFVFVVadeuXSooKJDD4dAdd9yhqKgof+fzm+seYhrEw7L8palrdvR4mV7570P6zX191eeG5jk80+GIVHFxhWq3vynX99kKH/+0QmKvfPfgloyfTd8Ec70YYgoAgO8uew1iTU2N97nZbNbw4cN/tj4sLMw/yYDr1K1DlELMJh3LK2+2DaJ09rrf0NsfUlXRt6rZ8ZZaTXxBJmuo0bEAAAAQhC7bIPbr1++SdxT1eDwymUw6evSoX4IB18tuC1GnuMhmfR3ieSZ7K4UOf0Q1Gxepbu8qhQ6bZnQkAAAABKHLNojbt29vqhyAXyR1jNL27Hw5XQ2yWnybCiXQWDrcJFtymuoPbVRIx96ydrvN6EgAAAAIMpdtEBMSEpoqB+AXSYnR2rIvV98XViipY7TRca6brf8EufK/VO3uPysk9gaZI2KMjgQAAIAg0rxPqQBXcGPi2RspHcsrNzZIIzGFWBQ2fIbkdqp25zvyeJj6AgAAAI2HBhFBLTLcpvi24TqWd9roKI3GHN1e9iEPyl1wVM7Dm42OAwAAgCBCg4igl9QxWsfyTl/XtCaBxtojVZYu/VW3f63cJceNjgMAAIAgQYOIoJeUGK2aOpfyTlYaHaXRmEwmhab+P5nCWqt2+x/kcdYZHQkAAABBgAYRQa97x/PXIQbPMFNJMoVGKPSOdDWcLlLdJ/9ldBwAAAAEARpEBL22rUPVJtIeNDeq+SlLws2y9hkt59Gdch7/zOg4AAAAaOZoEBH0TCaTkjpG65vccnk8wXMd4nn22ybJ3Laz6nb9UQ1Vp4yOAwAAgGaMBhEtQlJilMor63XydK3RURqdKcSi0JEz5HHVq3bnfzL1BQAAAK4ZDSJahO4doyVJx3LLDc3hLyHRHWQf/IDc+V/KmbPN6DgAAABopmgQ0SJ0aNdKrUItQXkd4nnWnnfI0rmf6vZ9KHfpD0bHAQAAQDNEg4gWwWwy6caEKH2TG1x3Mv0pk8kk+7BpMtlbqTbzD/K46o2OBAAAgGaGBhEtRlLHaP1YVq2KquBtnMyhkQodnq6GUwWq+2S10XEAAADQzNAgosXwXocYxMNMJcmS2EvW3qPkPLJdrhOHjI4DAACAZoQGES1Gl/aRslrMOpYXvMNMz7PfNknmmI6q3bVSDdXlRscBAABAM0GDiBbDEmJWt/jW+iZI72T6UyaLTaEjZsrjrFXtrpVBOf8jAAAAGh8NIlqU7h2j9UNRpWrrXUZH8buQmATZB/2r3Lk5cn75d6PjAAAAoBmgQUSLktQxSg0ej/6RX2F0lCZhvXmkQjr1Vd2nq+UuyzM6DgAAAAJckzSIGzZs0NixY3XXXXfpgw8++Nn6o0ePatKkSRo1apSefvppuVxnz+4UFBTowQcf1OjRo/Xoo4+qqqpKkrR//34NHDhQ48eP1/jx4zVv3rymOAwEgRs6RMlkCv4b1ZxnMpkUOuzXMtnCVbudqS8AAABweX5vEIuKirRs2TKtWrVKGRkZWr16tb799tsLtnnyySf17LPPasuWLfJ4PFqzZo0k6YUXXtCUKVO0efNm9erVS2+88YYkKScnR9OmTVNGRoYyMjK0cOFCfx8GgkSY3aJOsZEt4jrE88xhrRU6bLoaTuWpbt+HRscBAABAAPN7g7h3714NGjRI0dHRCg8P16hRo7R582bv+vz8fNXW1io5OVmSNHHiRG3evFlOp1P79+/XqFGjLlgunW0QP/74Y02YMEEzZ85UYWGhvw8DQaR7xyh9V1Ahl7vB6ChNxtKpj6y33CnnF9vkyj1sdBwAAAAEKL83iMXFxXI4HN7XsbGxKioquuR6h8OhoqIinTp1ShEREbJYLBcsl6TIyEhNnTpV69ev17BhwzR79mx/HwaCSFJitOpdDTrx4xmjozQp+8B/kblNomp3/qcaalrGNZgAAADwjcXfH3Cx2+ubTKYrrr/c+1588UXvsgceeECvvvqqzpw5o8jIyKvO1bZtxFVveykOx9V/Hs4KhJoNCrXqjfVfqOBUjQYlJxod54oas2b1k/9d+X/8nTxZf1G7f5l3wc9iMAmE71lzQr0AAMB5fm8Q4+LidODAAe/r4uJixcbGXrC+pKTE+/rkyZOKjY1VTEyMKisr5Xa7FRIS4l3e0NCgt956S4888ohCQkL+70Asvh1KaWmlGhqufW44hyNSJ0+2rDNQ1yuQahYXE66DXxXr9l7tjY5yWY1eM1OMbAPuU3XWKhX87//IdvOIxtt3gAik71lzEMz1MptNjfKfgQAAtCR+H2I6ZMgQZWVlqaysTDU1Ndq6datSU1O96xMSEmS325WdnS1JWr9+vVJTU2W1WpWSkqJNmzZdsNxsNmvbtm3asmWLd3nfvn0VFhbm70NBEOmeGKVjeeVqaIETyFt73aWQjr1Vl/Vfcp8qMDoOAAAAAojfG8S4uDjNnj1bU6dO1YQJE3TPPfeoT58+Sk9PV05OjiRpyZIlWrhwocaMGaOamhpNnTpVkvT8889rzZo1Gjt2rA4cOKDf/OY3kqRFixbp3XffVVpamtauXav58+f7+zAQZJISo1VV61JhSZXRUZqcd+oLa6hqM9+Ux+00OhIAAAAChMlzsYv9WgCGmDa9QKpZ8alqzX3rE/3bqB4a3i/B6DiX5M+auU4cUs2W12TtM1qhg+73y2cYIZC+Z81BMNeLIaYAAPjO72cQgUDkiA5TVIRNx/LKjY5iGEvnZFlvHiHn4c1y5X1pdBwAAAAEABpEtEgmk0ndE6N1LLfc6CiGsg/6V5mjO6h25ztqqA3Os0gAAAC4ejSIaLGSEqNUWlGn0tO1RkcxjMliV+iIGfLUVqpu1x8vOr0MAAAAWg4aRLRYSR2jJUnftOBhppIU0q6z7AMmy3XioJxf7TI6DgAAAAxEg4gWK9ERoTB7iI7lnTY6iuGsve9WSMItqstapYbyQqPjAAAAwCC+zS4PBBGz2aQbEqJ09MQpff3DKaPjXFRRRZ3Ky6ub5LPM3e9TbPFindq8QiWDnpDMl/71EB1pV1yb8CbJBQAAgKZDg4gWrWfnNvriu39o0aqDRkcJCL2tAzQ9cqeOZPxZG2r6X3bbmzpFa2T/RCV3b6cQM4MRAAAAggENIlq0O/t3VLf41tc1J6Y/RUWH63QTnUE8K1mVR2o1Mu9T9b09VXUx3S+61XeFFdp5MF8r1n2hNpF23dEvQcP6dlDrVrYmzAoAAIDGZvK00NsWlpZWXldTEMyTS/sLNfOdETXzOOtU9dfnJVedWk36D5lCLz7ReEODR5//o0SZ2Xn68vgpWUJMuu2mWI3on6hu8a1lMpmaNPd5fM98E8z1MptNatv24t9fAABwcZxBBHABk9WusBEzVZ3xH6rd/WeF3jnros2e2WxSv+4O9evuUGFplTI/y9fHOYXK+rJIXdpHamT/RA3oGSurJcSAowAAAMC14MIhAD8T4ugiW8okub4/INc3e664fXzbVnrwriS9OmuofnV3kuqcbq386KjmrNirD3d+q5LTNU2QGgAAANeLM4gALsrWd7TceTmq/fh9hbRPkjkq7orvCbNbNOLWRA3vl6CvfihXZnaeNn/6gzZ/+oOSb2ynEf0TdXPnNoYNPwUAAMDl0SACuCiTyazQO9JVtfZZ1WT+QeHjn5bpMlNfXPhek3p2bqOenduo9HStdh7K165DBTp4rETxbcM14tZEDenVXmF2fgUBAAAEEoaYArgkc0SMQm9/WA0nv1d9dsY17aNtVKgmDbtBr84aoun39FSY3aIPtn2jf1/xsd7b+rXyS6oaOTUAAACuFf99D+CyrN1uk7vH7ao/uFEhib1kie9xbfuxhGhIr3gN6RWv7wsrlJmdp92fF2rHZ/nq2bmNRtyaqOTubZlTEQAAwEBMc3GNgvnW8P5CzXwXKDXzOGtVtfZ5qcGlVpNelMneqlH2W1Fdr92fF2jnwXyVVtQpprVddyQnKPU65lQMlJo1F8FcL6a5AADAdzSI1yiY/1HlL9TMd4FUM3fxd6rOeEmWrv0VOvLRRr3RjLuhQZ9/W6rMz/J0xDunYpxG9k9Utw6tfdpXINWsOQjmetEgAgDgO4aYArgqIbHdZEuZoPr9a+V0dJHZ0bVR998nQuqTGqrSvm108JsS5Xx3WP/99SHFtw1Xv+4O3dQ5WpaQKw8/rakOl6u8ulGzBbPArZdJIbHdZLJc25lkAABwbWgQAVw1W980ufO+UN2na/z2GeGShkoaGiYpTJJT0hHJeeTs0ythxkXfBHK9bLeOlz3ll0bHAACgRaFBBHDVTGazwsbMkbv4O0lNMzrd45Fyi84o+5sSfZtfLkm6MSFKtyY51CkuUv880jU6OlzlAXlGLDAFbr1MCom7wegQAAC0ODSIAHxisthk6XBTk35mtwSp2626YE7Fvx2vVHzbhp/NqRjmiFRleHBeU+cP1AsAAPxUk9ykZsOGDXrzzTfldDr18MMP68EHH7xg/dGjR/XMM8+osrJSKSkpeuGFF2SxWFRQUKAnn3xSpaWl6tq1q5YsWaJWrVqpoqJCv/3tb5Wbm6uYmBi99tprcjgcPmXiJjVNj5r5jppdnNPl1r6jxcr8LF/fF1bIbgvR0F7tdUe/BPXo1k4lJZVGR2w22rWLUMXp6qCcXoSb1AAA4Du/N4hFRUV64IEH9Ne//lU2m03333+/li5dqhtvvNG7zT333KP58+crOTlZTz31lHr16qUpU6ZoxowZGjdunNLS0rRixQpVV1frySef1Isvvqj27dvrkUce0fr167Vz50699tprPuWiQWx61Mx31OzKviuoUOZnedp3tEgud4u8KXOjsISYZLeGyHbuYbeaZbeGeB+2c69t55fZQmSzmP/v+T9t99OH1WqWuRHvenu1aBABAPCd3xvEdevWaf/+/VqwYIEkacWKFfJ4PHrsscckSfn5+XrooYf097//XZJ04MABLV++XCtXrtTAgQO1b98+WSwWFRYW6le/+pW2b9+uESNG6IMPPlB8fLxcLpcGDBigTz/9VFar9apz0SA2PWrmO2p29Sqq6/XZ1ydltVtUWVlndJxmIzzcrlOnq1XndKu+vkF1TvfZ5+f+rHM2eJ/X/+S1r789bRbzFZrLn6w/9xjQM1YxrUOv+dhoEAEA8J3fr0EsLi6+YPhnbGysDh8+fMn1DodDRUVFOnXqlCIiImSxWC5Y/s/vsVgsioiIUFlZmeLi4q46V2P8o8HhiLzufbQ01Mx31OzqOCTd0Lmt0TFaBI/Hc7Z5rD/7qK13qbbe7V1WW+9SbZ1bdfUu1Tndqq0//3D97D3VdS6dqqw7u/7ce+pdDZKkyEi7Jgzz7fIBAABwffzeIF7sBOVPJ9i+1Porve+fmX28foYziE2PmvmOmvmOmvnmeutlkhQWYlJYmEUKa5y/Uho8HjmdDbLbQq4rG2cQAQDwnd/vShAXF6eSkhLv6+LiYsXGxl5y/cmTJxUbG6uYmBhVVlbK7XZfsFw6exby/HtcLpcqKysVHR3t70MBADQBs8kkuy3E6BgAALRIfm8QhwwZoqysLJWVlammpkZbt25Vamqqd31CQoLsdruys7MlSevXr1dqaqqsVqtSUlK0adOmC5ZL0rBhw7R+/XpJ0qZNm5SSkuLT9YcAAAAAgJ9rsmku3nrrLTmdTk2ePFnp6elKT0/X448/rt69e+urr77SM888o6qqKt18881auHChbDab8vPzNXfuXJWWlio+Pl5Lly5VVFSUysvLNXfuXOXm5ioyMlJLlixRYmKiT5kYYtr0qJnvqJnvqJlvgrleDDEFAMB3TdIgBiIaxKZHzXxHzXxHzXwTzPWiQQQAwHfBNzMyAAAAAOCa0CACAAAAACQ1wTQXgcpsvvSUGU25j5aGmvmOmvmOmvkmWOsVrMcFAIA/tdhrEAEAAAAAF2KIKQAAAABAEg0iAAAAAOAcGkQAAAAAgCQaRAAAAADAOTSIAAAAAABJNIgAAAAAgHNoEAEAAAAAkmgQAQAAAADn0CACAAAAACTRIAIAAAAAzqFB9NGGDRs0duxY3XXXXfrggw+MjtMsvP7660pLS1NaWpoWL15sdJxmZdGiRZo7d67RMZqFzMxMTZw4UaNHj9b8+fONjtMsZGRkeH82Fy1aZHQcAAAQAGgQfVBUVKRly5Zp1apVysjI0OrVq/Xtt98aHSug7d27V3v27NG6deu0fv16ffnll9q2bZvRsZqFrKwsrVu3zugYzUJubq6ef/55vfHGG9qwYYOOHDmiXbt2GR0roNXU1Oill17Se++9p4yMDB04cEB79+41OhYAADAYDaIP9u7dq0GDBik6Olrh4eEaNWqUNm/ebHSsgOZwODR37lzZbDZZrVbdcMMNKigoMDpWwCsvL9eyZcs0c+ZMo6M0C9u2bdPYsWPVvn17Wa1WLVu2TH379jU6VkBzu91qaGhQTU2NXC6XXC6X7Ha70bEAAIDBaBB9UFxcLIfD4X0dGxuroqIiAxMFvu7duys5OVmSdPz4cW3atEnDhg0zNlQz8Nxzz2n27Nlq3bq10VGahRMnTsjtduvXv/61xo0bp1WrVikqKsroWAEtIiJCTzzxhMaMGaPU1FQlJCTo1ltvNToWAAAwGA2iDzwez8+WmUwmA5I0P8eOHdO0adP0u9/9Tl26dDE6TkD78MMPFR8fr8GDBxsdpdlwu93KysrSK6+8ojVr1ignJ4fhuVfw1Vdfae3atdqxY4f27Nkjs9mslStXGh0LAAAYjAbRB3FxcSopKfG+Li4uVmxsrIGJmofs7Gw9/PDDmjNnjn75y18aHSfgbdq0SR9//LHGjx+v5cuXKzMzUwsWLDA6VkBr166dBg8erJiYGIWGhmrkyJE6fPiw0bEC2p49ezR48GC1bdtWNptNEydO1L59+4yOBQAADEaD6IMhQ4YoKytLZWVlqqmp0datW5Wammp0rIBWWFioWbNmacmSJUpLSzM6TrPwpz/9SRs3blRGRoYef/xxjRgxQk899ZTRsQLa8OHDtWfPHlVUVMjtdmv37t265ZZbjI4V0G666Sbt3btX1dXV8ng8yszMVO/evY2OBQAADGYxOkBzEhcXp9mzZ2vq1KlyOp2aPHmy+vTpY3SsgLZy5UrV1dXp5Zdf9i67//779cADDxiYCsGmb9++mj59uqZMmSKn06mhQ4dq0qRJRscKaL/4xS905MgRTZw4UVarVb1799YjjzxidCwAAGAwk+diF9YBAAAAAFochpgCAAAAACTRIAIAAAAAzqFBBAAAAABIokEEAAAAAJxDgwgAAAAAkESDCOAy8vLy1KNHD1VVVRkdBQAAAE2ABhEAAAAAIIkGETBcXl6eUlJS9Pbbb2vo0KEaPHiwFixYcMnt9+/fr0mTJiklJUX33XefDh8+7F3Xo0cPvf322xoyZIgGDhyopUuXqqGhQZJUUlKiOXPmaODAgRo2bJgWL16s+vp6SVJdXZ3mz5+vQYMGaeDAgZo3b57q6uq8+/3LX/6ikSNHqn///nr55Ze9yzds2KC7775bt912myZNmqQ9e/Y0dnkAAADQhGgQgQBw5swZ5eXlaceOHXrzzTe1atUqHTx48GfbFRQUaMaMGXr00Uf1ySefaNq0aUpPT1d5ebl3m507d2rjxo368MMPtXHjRq1evVqS9Nhjj0mStm/frjVr1mjfvn1avny5JOn3v/+9Dh06pIyMDG3fvl35+flasWKFd5/FxcX629/+pvfff1/vv/++srOzVVNTo3nz5mnp0qXav3+/pkyZomeffVYej8ePlQIAAIA/0SACASI9PV02m03Jycnq1q2bTpw48bNtNm7cqIEDB+rOO++UxWLRmDFjlJSUpC1btni3mTNnjmJiYtSpUydNnTpVH330kX744QcdPHhQTz/9tCIiIhQXF6cnnnhC69atkyR99NFHmjlzpuLi4hQREaHFixdr8uTJ3n3OmDFDNptNPXv2VNeuXZWXlydJstvtWrNmjQ4ePKjx48crMzNTJpPJz5UCAACAv9AgAgEiJibG+9xisXiHhv5UQUGBdu/erZSUFO8jJydHhYWF3m06d+7sfd6+fXudPHlSpaWlCg8Pv+AzOnTooJKSEjmdTpWUlKh9+/YXvK9Tp07e161bt/Y+t1qtcrvdCgsL07vvvquysjJNnz5dQ4cO1TvvvHP9hQAAAIBhLEYHAHD1HA6Hxo4dq8WLF3uX5ebmqk2bNt7XxcXFateunaSzDWV8fLw6dOig6upqlZWVeZvEvLw8RUdHy2q1Ki4uTkVFRerVq5ckKScnR4cOHdLw4cMvmaWyslJVVVV6/fXX5XK5tHfvXs2aNUsDBgxQcnKyH44eAAAA/sYZRKAZSUtL044dO5SVlSWPx6Ps7GyNGzdOOTk53m2WL1+uyspKff/993rvvfc0YcIExcXFafDgwXrppZdUVVWloqIiLV++XPfee68k6d5779Xbb7+tkpISnTlzRq+++qpKSkoum6W6ulrTp0/X7t27ZbFYFBsbK5PJpKioKL/WAAAAAP7DGUSgGenSpYtee+01vfLKKzp+/LhiYmI0b948DR482LtNYmKi0tLS5Ha79dBDD2nChAmSpCVLluill17SyJEjJUnjxo3TnDlzJEmPPvqoampqNGHCBLlcLo0ePVqzZs1ScXHxJbPExsZq8eLFWrBggX788Ue1adNGzz33nLp27eq/AgAAAMCvTB5uOQgEjR49emjDhg1KSkoyOgoAAACaIYaYAgAAAAAk0SACAAAAAM5hiCkAAAAAQBJnEAEAAAAA59AgAgAAAAAk0SACAAAAAM6hQQQAAAAASKJBBAAAAACc8/8BUhZ6ffdUg3MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x576 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(trainer.history['train_loss'], label=\"train\")\n",
    "plt.plot(trainer.history['val_loss'], label=\"val\")\n",
    "plt.legend(fontsize=13)\n",
    "plt.xlabel(\"n epochs\", fontsize=13)\n",
    "plt.ylabel(\"Loss\", fontsize=13)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(trainer.history['train_acc'], label=\"train\")\n",
    "plt.plot(trainer.history['val_acc'], label=\"val\")\n",
    "plt.legend(fontsize=13)\n",
    "plt.xlabel(\"n epochs\", fontsize=13)\n",
    "plt.ylabel(\"Accuracy\", fontsize=13)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(trainer.lr_history['lr_wide_0'], label=\"wide\")\n",
    "plt.plot(trainer.lr_history['lr_deeptabular_0'], label=\"deeptabular\")\n",
    "plt.legend(fontsize=13)\n",
    "plt.xlabel(\"n epochs\", fontsize=13)\n",
    "plt.ylabel(\"learning rate\", fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plots, the learning rate effectively decreases by a factor of 0.1 (the default) after the corresponding `step_size` for each component. Note that the keys in the `model.lr_history` dictionary have a suffix `_0`. This is because if you pass different parameter groups to the torch optimizers, these will also be recorded. We'll see this in the regression example later in the post.\n",
    "\n",
    "Before I move to the next section let me just mention that the `WideDeep` class comes with a useful method to \"rescue\" the learned embeddings, very creatively called `get_embeddings`. For example, let's say I want to use the embeddings learned for the different levels of the categorical feature `education`. These can be access via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41479743,  0.08521606,  0.2710749 , -0.17924106, -0.07241581,\n",
       "       -0.2514616 , -0.24809864, -0.20624267, -0.12701468, -0.00737057,\n",
       "       -0.17397854,  0.03000254, -0.06039784,  0.28008303, -0.35625017,\n",
       "        0.00706905,  0.18486224, -0.05701892, -0.05574326, -0.08269893,\n",
       "       -0.15482767,  0.30681178, -0.23743518,  0.08368678,  0.20123835,\n",
       "        0.30058601, -0.15073103, -0.08352864,  0.07049613, -0.28594372,\n",
       "       -0.05307232, -0.17094977], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_embed = trainer.get_embeddings(\n",
    "    col_name='education', \n",
    "    cat_encoding_dict=tab_preprocessor.label_encoder.encoding_dict\n",
    ")\n",
    "education_embed['doctorate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using the Focal Loss\n",
    "\n",
    "The Focal loss (hereafter FL) was introduced by Tsung-Yi Lin et al., in their [2018 paper](https://arxiv.org/pdf/1708.02002.pdf) Focal Loss for Dense Object Detection [1]. It is designed to address scenarios with extreme imbalanced classes, such as one-stage object detection where the imbalance between foreground and background classes can be, for example, 1:1000.\n",
    "\n",
    "The adult census dataset is not really imbalanced, therefore is not the best dataset to test the performance of the FL. Nonetheless, let me illustrate how easy is to use the FL with `pytorch-widedeep`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideDeep(wide=wide, deeptabular=deeptabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    objective=\"binary_focal_loss\",\n",
    "    optimizers=optimizers, \n",
    "    lr_schedulers=schedulers, \n",
    "    initializers=initializers,\n",
    "    callbacks=callbacks,\n",
    "    metrics=metrics,\n",
    "    alpha=0.2, # the alpha parameter of the focal loss\n",
    "    gamma=1.0, # the gamma parameter of the focal loss\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(X_wide=X_wide, X_tab=X_tab, target=target, n_epochs=2, batch_size=256, val_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the losses available at `pytorch-widedeep` have a look at the `losses` module in the library or the [docs](https://pytorch-widedeep.readthedocs.io/en/latest/losses.html).\n",
    "\n",
    "## 3. Regression combining tabular data, text and images\n",
    "\n",
    "For this example we will use a small sample (so you can run it locally in a laptop) of the [Airbnb listings dataset](http://insideairbnb.com/get-the-data.html) in London. \n",
    "\n",
    "In case you are interested in all details, I did prepared the original dataset for this post, and all the code can be found at the `airbnb_data_preprocessing.py`, [here](`https://github.com/jrzaurin/pytorch-widedeep/blob/master/examples/airbnb_data_preprocessing.py`). After such preprocessing the data looks like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "airbnb = pd.read_csv('data/airbnb/airbnb_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>description</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>is_location_exact</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>has_house_rules</th>\n",
       "      <th>host_gender</th>\n",
       "      <th>accommodates_catg</th>\n",
       "      <th>guests_included_catg</th>\n",
       "      <th>minimum_nights_catg</th>\n",
       "      <th>host_listings_count_catg</th>\n",
       "      <th>bathrooms_catg</th>\n",
       "      <th>bedrooms_catg</th>\n",
       "      <th>beds_catg</th>\n",
       "      <th>amenity_24-hour_check-in</th>\n",
       "      <th>amenity__toilet</th>\n",
       "      <th>amenity_accessible-height_bed</th>\n",
       "      <th>amenity_accessible-height_toilet</th>\n",
       "      <th>amenity_air_conditioning</th>\n",
       "      <th>amenity_air_purifier</th>\n",
       "      <th>amenity_alfresco_bathtub</th>\n",
       "      <th>amenity_amazon_echo</th>\n",
       "      <th>amenity_baby_bath</th>\n",
       "      <th>amenity_baby_monitor</th>\n",
       "      <th>amenity_babysitter_recommendations</th>\n",
       "      <th>amenity_balcony</th>\n",
       "      <th>amenity_bath_towel</th>\n",
       "      <th>amenity_bathroom_essentials</th>\n",
       "      <th>amenity_bathtub</th>\n",
       "      <th>amenity_bathtub_with_bath_chair</th>\n",
       "      <th>amenity_bbq_grill</th>\n",
       "      <th>amenity_beach_essentials</th>\n",
       "      <th>amenity_beach_view</th>\n",
       "      <th>amenity_beachfront</th>\n",
       "      <th>amenity_bed_linens</th>\n",
       "      <th>amenity_bedroom_comforts</th>\n",
       "      <th>...</th>\n",
       "      <th>amenity_roll-in_shower</th>\n",
       "      <th>amenity_room-darkening_shades</th>\n",
       "      <th>amenity_safety_card</th>\n",
       "      <th>amenity_sauna</th>\n",
       "      <th>amenity_self_check-in</th>\n",
       "      <th>amenity_shampoo</th>\n",
       "      <th>amenity_shared_gym</th>\n",
       "      <th>amenity_shared_hot_tub</th>\n",
       "      <th>amenity_shared_pool</th>\n",
       "      <th>amenity_shower_chair</th>\n",
       "      <th>amenity_single_level_home</th>\n",
       "      <th>amenity_ski-in_ski-out</th>\n",
       "      <th>amenity_smart_lock</th>\n",
       "      <th>amenity_smart_tv</th>\n",
       "      <th>amenity_smoke_detector</th>\n",
       "      <th>amenity_smoking_allowed</th>\n",
       "      <th>amenity_soaking_tub</th>\n",
       "      <th>amenity_sound_system</th>\n",
       "      <th>amenity_stair_gates</th>\n",
       "      <th>amenity_stand_alone_steam_shower</th>\n",
       "      <th>amenity_standing_valet</th>\n",
       "      <th>amenity_steam_oven</th>\n",
       "      <th>amenity_stove</th>\n",
       "      <th>amenity_suitable_for_events</th>\n",
       "      <th>amenity_sun_loungers</th>\n",
       "      <th>amenity_table_corner_guards</th>\n",
       "      <th>amenity_tennis_court</th>\n",
       "      <th>amenity_terrace</th>\n",
       "      <th>amenity_toilet_paper</th>\n",
       "      <th>amenity_touchless_faucets</th>\n",
       "      <th>amenity_tv</th>\n",
       "      <th>amenity_walk-in_shower</th>\n",
       "      <th>amenity_warming_drawer</th>\n",
       "      <th>amenity_washer</th>\n",
       "      <th>amenity_washer_dryer</th>\n",
       "      <th>amenity_waterfront</th>\n",
       "      <th>amenity_well-lit_path_to_entrance</th>\n",
       "      <th>amenity_wheelchair_accessible</th>\n",
       "      <th>amenity_wide_clearance_to_shower</th>\n",
       "      <th>amenity_wide_doorway_to_guest_bathroom</th>\n",
       "      <th>amenity_wide_entrance</th>\n",
       "      <th>amenity_wide_entrance_for_guests</th>\n",
       "      <th>amenity_wide_entryway</th>\n",
       "      <th>amenity_wide_hallways</th>\n",
       "      <th>amenity_wifi</th>\n",
       "      <th>amenity_window_guards</th>\n",
       "      <th>amenity_wine_cooler</th>\n",
       "      <th>security_deposit</th>\n",
       "      <th>extra_people</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13913.jpg</td>\n",
       "      <td>54730</td>\n",
       "      <td>My bright double bedroom with a large window has a relaxed feeling! It comfortably fits one or t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>f</td>\n",
       "      <td>Islington</td>\n",
       "      <td>51.56802</td>\n",
       "      <td>-0.11121</td>\n",
       "      <td>t</td>\n",
       "      <td>apartment</td>\n",
       "      <td>private_room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  host_id  \\\n",
       "0  13913.jpg    54730   \n",
       "\n",
       "                                                                                           description  \\\n",
       "0  My bright double bedroom with a large window has a relaxed feeling! It comfortably fits one or t...   \n",
       "\n",
       "   host_listings_count host_identity_verified neighbourhood_cleansed  \\\n",
       "0                  4.0                      f              Islington   \n",
       "\n",
       "   latitude  longitude is_location_exact property_type     room_type  \\\n",
       "0  51.56802   -0.11121                 t     apartment  private_room   \n",
       "\n",
       "   accommodates  bathrooms  bedrooms  beds  guests_included  minimum_nights  \\\n",
       "0             2        1.0       1.0   0.0                1               1   \n",
       "\n",
       "  instant_bookable cancellation_policy  has_house_rules host_gender  \\\n",
       "0                f            moderate                1      female   \n",
       "\n",
       "   accommodates_catg  guests_included_catg  minimum_nights_catg  \\\n",
       "0                  2                     1                    1   \n",
       "\n",
       "   host_listings_count_catg  bathrooms_catg  bedrooms_catg  beds_catg  \\\n",
       "0                         3               1              1          0   \n",
       "\n",
       "   amenity_24-hour_check-in  amenity__toilet  amenity_accessible-height_bed  \\\n",
       "0                         0                0                              1   \n",
       "\n",
       "   amenity_accessible-height_toilet  amenity_air_conditioning  \\\n",
       "0                                 1                         0   \n",
       "\n",
       "   amenity_air_purifier  amenity_alfresco_bathtub  amenity_amazon_echo  \\\n",
       "0                     0                         0                    0   \n",
       "\n",
       "   amenity_baby_bath  amenity_baby_monitor  \\\n",
       "0                  0                     0   \n",
       "\n",
       "   amenity_babysitter_recommendations  amenity_balcony  amenity_bath_towel  \\\n",
       "0                                   1                0                   0   \n",
       "\n",
       "   amenity_bathroom_essentials  amenity_bathtub  \\\n",
       "0                            0                1   \n",
       "\n",
       "   amenity_bathtub_with_bath_chair  amenity_bbq_grill  \\\n",
       "0                                1                  0   \n",
       "\n",
       "   amenity_beach_essentials  amenity_beach_view  amenity_beachfront  \\\n",
       "0                         0                   0                   0   \n",
       "\n",
       "   amenity_bed_linens  amenity_bedroom_comforts  ...  amenity_roll-in_shower  \\\n",
       "0                   1                         0  ...                       1   \n",
       "\n",
       "   amenity_room-darkening_shades  amenity_safety_card  amenity_sauna  \\\n",
       "0                              1                    0              0   \n",
       "\n",
       "   amenity_self_check-in  amenity_shampoo  amenity_shared_gym  \\\n",
       "0                      0                1                   0   \n",
       "\n",
       "   amenity_shared_hot_tub  amenity_shared_pool  amenity_shower_chair  \\\n",
       "0                       0                    0                     0   \n",
       "\n",
       "   amenity_single_level_home  amenity_ski-in_ski-out  amenity_smart_lock  \\\n",
       "0                          0                       0                   0   \n",
       "\n",
       "   amenity_smart_tv  amenity_smoke_detector  amenity_smoking_allowed  \\\n",
       "0                 0                       1                        1   \n",
       "\n",
       "   amenity_soaking_tub  amenity_sound_system  amenity_stair_gates  \\\n",
       "0                    0                     0                    0   \n",
       "\n",
       "   amenity_stand_alone_steam_shower  amenity_standing_valet  \\\n",
       "0                                 0                       0   \n",
       "\n",
       "   amenity_steam_oven  amenity_stove  amenity_suitable_for_events  \\\n",
       "0                   0              1                            0   \n",
       "\n",
       "   amenity_sun_loungers  amenity_table_corner_guards  amenity_tennis_court  \\\n",
       "0                     0                            0                     0   \n",
       "\n",
       "   amenity_terrace  amenity_toilet_paper  amenity_touchless_faucets  \\\n",
       "0                0                     0                          0   \n",
       "\n",
       "   amenity_tv  amenity_walk-in_shower  amenity_warming_drawer  amenity_washer  \\\n",
       "0           1                       0                       0               1   \n",
       "\n",
       "   amenity_washer_dryer  amenity_waterfront  \\\n",
       "0                     0                   0   \n",
       "\n",
       "   amenity_well-lit_path_to_entrance  amenity_wheelchair_accessible  \\\n",
       "0                                  0                              0   \n",
       "\n",
       "   amenity_wide_clearance_to_shower  amenity_wide_doorway_to_guest_bathroom  \\\n",
       "0                                 0                                       1   \n",
       "\n",
       "   amenity_wide_entrance  amenity_wide_entrance_for_guests  \\\n",
       "0                      1                                 0   \n",
       "\n",
       "   amenity_wide_entryway  amenity_wide_hallways  amenity_wifi  \\\n",
       "0                      0                      0             1   \n",
       "\n",
       "   amenity_window_guards  amenity_wine_cooler  security_deposit  extra_people  \\\n",
       "0                      0                    0             100.0          15.0   \n",
       "\n",
       "   yield  \n",
       "0   12.0  \n",
       "\n",
       "[1 rows x 223 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define what will go through the wide and deep components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a number of columns that are already binary. Therefore, no need to one hot encode them\n",
    "crossed_cols = [('property_type', 'room_type')]\n",
    "already_dummies = [c for c in airbnb.columns if 'amenity' in c] + ['has_house_rules']\n",
    "wide_cols = ['is_location_exact', 'property_type', 'room_type', 'host_gender',\n",
    "'instant_bookable'] + already_dummies\n",
    "cat_embed_cols = [(c, 16) for c in airbnb.columns if 'catg' in c] + \\\n",
    "    [('neighbourhood_cleansed', 64), ('cancellation_policy', 16)]\n",
    "continuous_cols = ['latitude', 'longitude', 'security_deposit', 'extra_people']\n",
    "# it does not make sense to standarised Latitude and Longitude. Here I am going to \"pass\" but you \n",
    "# might want to check the LatLongScalarEnc available in the autogluon tabular library.\n",
    "already_standard = ['latitude', 'longitude']\n",
    "# text and image colnames\n",
    "text_col = 'description'\n",
    "img_col = 'id'\n",
    "# path to pretrained word embeddings and the images\n",
    "word_vectors_path = 'data/glove.6B/glove.6B.100d.txt'\n",
    "img_path = 'data/airbnb/property_picture'\n",
    "# target\n",
    "target_col = 'yield'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following: columns that are already dummies (defined as `already_dummies`), are treated as any other wide column. Internally, nothing will really happen to them. They will just add one entry to the embedding lookup table. \n",
    "\n",
    "On the other hand, you will see that among the columns that will be passed through the `deeptabular` component we have `already_standard` columns, which are longitude and latitude in this case. These are columns for which it makes no sense to standardize them via `sklearn`'s `StandardScaler`, which is what `TabPreprocessor` uses internally.  A solution would be to pre-process them before-hand (using for example the [LatLongScalarEnc](https://github.com/awslabs/autogluon/blob/master/tabular/src/autogluon/tabular/models/tab_transformer/tab_transformer_encoder.py) available at the `autogluon` library) and then pass them to the `TabPreprocessor`. \n",
    "\n",
    "Nonetheless, in this case I am going to \"ignore\" this issue and move on since I just want to illustrate the use of the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor, TextPreprocessor, ImagePreprocessor\n",
    "from pytorch_widedeep.models import Wide, TabMlp, DeepText, DeepImage, WideDeep\n",
    "from pytorch_widedeep.initializers import *\n",
    "from pytorch_widedeep.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary contains 2192 tokens\n",
      "Indexing word vectors...\n",
      "Loaded 400000 word vectors\n",
      "Preparing embeddings matrix...\n",
      "2175 words in the vocabulary had data/glove.6B/glove.6B.100d.txt vectors and appear more than 5 times\n",
      "Reading Images from data/airbnb/property_picture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 36/1001 [00:00<00:02, 346.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1001/1001 [00:02<00:00, 372.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing normalisation metrics\n"
     ]
    }
   ],
   "source": [
    "target = airbnb[target_col].values\n",
    "\n",
    "wide_preprocessor = WidePreprocessor(wide_cols=wide_cols, crossed_cols=crossed_cols)\n",
    "X_wide = wide_preprocessor.fit_transform(airbnb)\n",
    "\n",
    "tab_preprocessor = TabPreprocessor(embed_cols=cat_embed_cols, continuous_cols=continuous_cols)\n",
    "X_tab = tab_preprocessor.fit_transform(airbnb)\n",
    "\n",
    "text_preprocessor = TextPreprocessor(word_vectors_path=word_vectors_path, text_col=text_col)\n",
    "X_text = text_preprocessor.fit_transform(airbnb)\n",
    "\n",
    "image_processor = ImagePreprocessor(img_col = img_col, img_path = img_path)\n",
    "X_images = image_processor.fit_transform(airbnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage the data is ready to be passed through the model. However, instead of building a \"simple\" model that collects the `wide`, `deeptabular`, `deeptext` and `deepimage` component, I am going to use this opportunity to illustrate `pytorch-widedepp`'s flexibility to build wide and deep models. I like to call this, getting into *Kaggle mode*.\n",
    "\n",
    "First we define the components of the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "\n",
    "# deeptabular: 2 Dense layers\n",
    "deeptabular = TabMlp(\n",
    "    column_idx = tab_preprocessor.column_idx,\n",
    "    mlp_hidden_dims=[128,64],\n",
    "    mlp_dropout = 0.1,\n",
    "    mlp_batchnorm = True,\n",
    "    embed_input=tab_preprocessor.embeddings_input,\n",
    "    embed_dropout = 0.1,\n",
    "    continuous_cols = continuous_cols,\n",
    "    batchnorm_cont = True\n",
    ")\n",
    "    \n",
    "# deeptext: a stack of 2 LSTMs\n",
    "deeptext = DeepText(\n",
    "    vocab_size=len(text_preprocessor.vocab.itos), \n",
    "    hidden_dim=64, \n",
    "    n_layers=2,\n",
    "    rnn_dropout=0.5, \n",
    "    embed_matrix=text_preprocessor.embedding_matrix)\n",
    "\n",
    "# Pretrained Resnet 18 (default is all but last 2 conv blocks frozen) plus a FC-Head 512->256->128\n",
    "deepimage = DeepImage(pretrained=True, head_hidden_dims=[512, 256, 128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and, as we build the model, add a fully connected *head* via the input parameters (could also be used via the additional component/parameter `deephead`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideDeep(\n",
    "    wide=wide, \n",
    "    deeptabular=deeptabular, \n",
    "    deeptext=deeptext, \n",
    "    deepimage=deepimage, \n",
    "    head_hidden_dims=[128, 64]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WideDeep(\n",
       "  (wide): Wide(\n",
       "    (wide_linear): Embedding(357, 1, padding_idx=0)\n",
       "  )\n",
       "  (deeptabular): TabMlp(\n",
       "    (embed_layers): ModuleDict(\n",
       "      (emb_layer_accommodates_catg): Embedding(4, 16, padding_idx=0)\n",
       "      (emb_layer_bathrooms_catg): Embedding(4, 16, padding_idx=0)\n",
       "      (emb_layer_bedrooms_catg): Embedding(5, 16, padding_idx=0)\n",
       "      (emb_layer_beds_catg): Embedding(5, 16, padding_idx=0)\n",
       "      (emb_layer_cancellation_policy): Embedding(6, 16, padding_idx=0)\n",
       "      (emb_layer_guests_included_catg): Embedding(4, 16, padding_idx=0)\n",
       "      (emb_layer_host_listings_count_catg): Embedding(5, 16, padding_idx=0)\n",
       "      (emb_layer_minimum_nights_catg): Embedding(4, 16, padding_idx=0)\n",
       "      (emb_layer_neighbourhood_cleansed): Embedding(33, 64, padding_idx=0)\n",
       "    )\n",
       "    (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "    (norm): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (tab_mlp): MLP(\n",
       "      (mlp): Sequential(\n",
       "        (dense_layer_0): Sequential(\n",
       "          (0): BatchNorm1d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): Dropout(p=0.1, inplace=False)\n",
       "          (2): Linear(in_features=196, out_features=128, bias=False)\n",
       "          (3): ReLU(inplace=True)\n",
       "        )\n",
       "        (dense_layer_1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (deeptext): DeepText(\n",
       "    (word_embed): Embedding(2192, 100, padding_idx=1)\n",
       "    (rnn): LSTM(100, 64, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  )\n",
       "  (deepimage): DeepImage(\n",
       "    (backbone): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    )\n",
       "    (imagehead): MLP(\n",
       "      (mlp): Sequential(\n",
       "        (dense_layer_0): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (dense_layer_1): Sequential(\n",
       "          (0): Dropout(p=0.1, inplace=False)\n",
       "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (deephead): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (dense_layer_0): Sequential(\n",
       "        (0): Dropout(p=0.1, inplace=False)\n",
       "        (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (dense_layer_1): Sequential(\n",
       "        (0): Dropout(p=0.1, inplace=False)\n",
       "        (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (head_out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a big model, so let me go component by component. \n",
    "\n",
    "1. `wide`: simple linear model implemented via an `Embedding` layer\n",
    "\n",
    "2. `deeptabular`: embeddings concatenated to categorical columns that are then passed through two dense layers with the following sizes [196 $\\rightarrow$ 128 $\\rightarrow$ 64]. \n",
    "\n",
    "3. `deeptext`: two stacked LTSMs that will received the pre-trained glove wordvectors and output a last hidden state of dim 64 (this would be 128 if we had used `bidirectional = True`)\n",
    "\n",
    "4. `deepimage`: a pre-trained ResNet 18 model where only the last `Sequential` block (7) will be trained. The rest will remain \"frozen\". on top of it we have `imagehead` which is just a `Sequential` model comprised of two dense layers with the following sizes [512 $\\rightarrow$ 256 $\\rightarrow$ 128]\n",
    "\n",
    "5. `deephead`: on top of the 3 deep components we have a final component referred as `deephead`. This component will receive the concatenated output from all the deep components, and pass it through a further collection of dense layers. In this case the sizes are [256 $\\rightarrow$ 64 $\\rightarrow$ 1]. We input 256 because the output dim from `deeptabular` is 64, the  output dim from `deeptext` is 64 and the output dim from `deepimage` is 128. The final `deephead` output dim is 1 because we are performing a regression, i.e. one output neuron with no activation function. \n",
    "\n",
    "Let's go even a step further and use different optimizers, initializers and schedulers for different components. Moreover, let's use a different learning rate for different parameter groups in the case of the `deeptabular`, remember, this is *Kaggle mode*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizers. Different parameter groups for the deeptabular component will use different lr\n",
    "tab_params = []\n",
    "for childname, child in model.named_children():\n",
    "    if childname == 'deeptabular':\n",
    "        for n,p in child.named_parameters():\n",
    "            if \"emb_layer\" in n: tab_params.append({'params': p, 'lr': 0.01})\n",
    "            else: tab_params.append({'params': p, 'lr': 0.03})\n",
    "                \n",
    "wide_opt = torch.optim.Adam(model.wide.parameters(), lr=0.03)\n",
    "tab_opt = torch.optim.Adam(tab_params)\n",
    "text_opt = RAdam(model.deeptext.parameters())\n",
    "img_opt  = RAdam(model.deepimage.parameters())\n",
    "head_opt = torch.optim.AdamW(model.deephead.parameters())\n",
    "optimizers = {'wide': wide_opt, 'deeptabular':tab_opt, 'deeptext':text_opt, 'deepimage': img_opt, 'deephead': head_opt}\n",
    "\n",
    "# schedulers\n",
    "wide_sch = torch.optim.lr_scheduler.StepLR(wide_opt, step_size=5)\n",
    "deep_sch = torch.optim.lr_scheduler.MultiStepLR(tab_opt, milestones=[3,8])\n",
    "text_sch = torch.optim.lr_scheduler.StepLR(text_opt, step_size=5)\n",
    "img_sch  = torch.optim.lr_scheduler.MultiStepLR(tab_opt, milestones=[3,8])\n",
    "head_sch = torch.optim.lr_scheduler.StepLR(head_opt, step_size=5)\n",
    "schedulers = {'wide': wide_sch, 'deeptabular':deep_sch, 'deeptext':text_sch, 'deepimage': img_sch, 'deephead': head_sch}\n",
    "\n",
    "# initializers\n",
    "initializers = {'wide': KaimingNormal, 'deeptabular':KaimingNormal, \n",
    "                'deeptext':KaimingNormal(pattern=r\"^(?!.*word_embed).*$\"), # do not initialize the pre-trained word-vectors!\n",
    "                'deepimage':KaimingNormal}\n",
    "\n",
    "# transforms and callbacks\n",
    "mean = [0.406, 0.456, 0.485]  #BGR\n",
    "std =  [0.225, 0.224, 0.229]  #BGR\n",
    "transforms = [ToTensor, Normalize(mean=mean, std=std)]\n",
    "callbacks = [LRHistory(n_epochs=10), EarlyStopping, ModelCheckpoint(filepath='model_weights/wd_out')]                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, since we will use pre-trained word embeddings, we do not want to initialize these embeddings. However you might still want to initialize the other layers in the `deeptext` component. This is not a problem, you can do that with the parameter `pattern` and your knowledge on regular  expressions. In the `deeptext` initializer definition above:\n",
    "\n",
    "```python\n",
    "KaimingNormal(pattern=r\"^(?!.*word_embed).*$\")\n",
    "```\n",
    "\n",
    "I am NOT initializing parameters whose name contains the string `word_embed`. \n",
    "\n",
    "So...let's compile and run, which is as easy as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, objective=\"regression\", initializers=initializers, optimizers=optimizers,\n",
    "    lr_schedulers=schedulers, callbacks=callbacks, transforms=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|| 25/25 [02:11<00:00,  5.28s/it, loss=1.27e+4]\n",
      "valid: 100%|| 7/7 [00:15<00:00,  2.25s/it, loss=9.2e+3] \n"
     ]
    }
   ],
   "source": [
    "trainer.fit(X_wide=X_wide, X_tab=X_tab, X_text=X_text, X_img=X_images,\n",
    "    target=target, n_epochs=1, batch_size=32, val_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned early in the post, please, **do not focus on the success metric/loss** (`mse` in this case). I am just using a very small sample of the dataset and some \"random\" set up. I just want to illustrate usability. A benchmark post will come in the \"no-so-distant future\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Finetune/Warmup routines\n",
    "\n",
    "\n",
    "Let's place ourselves in two possible scenarios.\n",
    "\n",
    "1. Let's assume we have run a model and we want to just transfer the learnings (you know...transfer-learning) to another dataset, or simply we have received new data and we do not want to start the training of each component from scratch. Simply, we want to load the pre-trained weights and fine-tune.\n",
    "\n",
    "2. Or, we just want to \"warm up\" individual model components individually before the joined training begins.\n",
    "\n",
    "This can be done with the `finetune` set of parameters (aliased all as `warmup` parameters if you wanted). There are 3 fine-tuning routines:\n",
    "\n",
    "1. Fine-tune all trainable layers at once with a triangular one-cycle learning rate (referred as slanted triangular learning rates in Howard & Ruder 2018)\n",
    "\n",
    "2. Gradual fine-tuning inspired by the work of Felbo et al., 2017 [2]\n",
    "\n",
    "3. Gradual fine-tuning based on the work of Howard & Ruder 2018 [3]\n",
    "\n",
    "Currently fine-tunning is only supported without a fully connected head, i.e. if `deephead=None`. In addition, Felbo and Howard routines apply only, of course, to the `deeptabular`, `deeptext` and `deepimage `models. The `wide` component can also be fine-tuned, but only in an \"all at once\" mode.\n",
    "\n",
    "\n",
    "Let me briefly describe the \"Felbo\" and \"Howard\" routines before showing how to use them.\n",
    "\n",
    "### 4.1 The Felbo finetune routine\n",
    "\n",
    "The Felbo fine-tune routine can be illustrated by the following figure:\n",
    "\n",
    "<img src=\"figures/pytorch-widedeep/felbo_routine.png\" alt=\"resnet_block\" width=\"500\"/>\n",
    "\n",
    "**Figure 1**. The figure can be described as follows: fine-tune (or train) the last layer for one epoch using a one cycle triangular learning rate. Then fine-tune the next deeper layer for one epoch, with a learning rate that is a factor of 2.5 lower than the previous learning rate (the 2.5 factor is fixed) while freezing the already warmed up layer(s). Repeat untill all individual layers are warmed. Then warm one last epoch with all warmed layers trainable. The vanishing color gradient in the figure attempts to illustrate the decreasing learning rate.\n",
    "\n",
    "Note that this is not identical to the Fine-Tunning routine described in Felbo et al, 2017, this is why I used the word 'inspired'.\n",
    "\n",
    "\n",
    "### 4.2 The Howard finetune routine\n",
    "\n",
    "The Howard routine can be illustrated by the following figure:\n",
    "\n",
    "<img src=\"figures/pytorch-widedeep/howard_routine.png\" alt=\"resnet_block\" width=\"500\"/>\n",
    "\n",
    "**Figure 2**. The figure can be described as follows: fine-tune (or train) the last layer for one epoch using a one cycle triangular learning rate. Then fine-tune the next deeper layer for one epoch, with a learning rate that is a factor of 2.5 lower than the previous learning rate (the 2.5 factor is fixed) while keeping the already warmed up layer(s) trainable. Repeat. The vanishing color gradient in the figure attempts to illustrate the decreasing learning rate.\n",
    "\n",
    "Note that I write \"fine-tune (or train) the last layer for one epoch [...]\". However, in practice the user will have to specify the order of the layers to be fine-tuned. This is another reason why I wrote that the fine-tune routines I have implemented are inspired by the work of Felbo and Howard and not identical to their implemenations.\n",
    "\n",
    "\n",
    "The felbo and howard routines can be accessed with via the [finetune parameters](https://pytorch-widedeep.readthedocs.io/en/latest/trainer.html) (aliased as `warmup` parameters in case the user wants to use consistent naming). Let me go back to the adult dataset and let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_cols = ['education', 'relationship','workclass','occupation','native_country','gender']\n",
    "crossed_cols = [('education', 'occupation'), ('native_country', 'occupation')]\n",
    "cat_embed_cols = [('education',32), ('relationship',32), ('workclass',32), ('occupation',32),('native_country',32)]\n",
    "continuous_cols = [\"age\",\"hours_per_week\"]\n",
    "target_col = 'income_label'\n",
    "\n",
    "# TARGET\n",
    "target = adult[target_col].values\n",
    "\n",
    "# WIDE\n",
    "wide_preprocessor = WidePreprocessor(wide_cols=wide_cols, crossed_cols=crossed_cols)\n",
    "X_wide = wide_preprocessor.fit_transform(adult)\n",
    "\n",
    "# DEEP\n",
    "tab_preprocessor = TabPreprocessor(embed_cols=cat_embed_cols, continuous_cols=continuous_cols)\n",
    "X_tab = tab_preprocessor.fit_transform(adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "deeptabular = TabResnet(\n",
    "    blocks_dims=[128, 64, 32], \n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    embed_input=tab_preprocessor.embeddings_input,\n",
    "    continuous_cols=continuous_cols)\n",
    "model = WideDeep(wide=wide, deeptabular=deeptabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WideDeep(\n",
       "  (wide): Wide(\n",
       "    (wide_linear): Embedding(797, 1, padding_idx=0)\n",
       "  )\n",
       "  (deeptabular): Sequential(\n",
       "    (0): TabResnet(\n",
       "      (embed_layers): ModuleDict(\n",
       "        (emb_layer_education): Embedding(17, 32, padding_idx=0)\n",
       "        (emb_layer_native_country): Embedding(43, 32, padding_idx=0)\n",
       "        (emb_layer_occupation): Embedding(16, 32, padding_idx=0)\n",
       "        (emb_layer_relationship): Embedding(7, 32, padding_idx=0)\n",
       "        (emb_layer_workclass): Embedding(10, 32, padding_idx=0)\n",
       "      )\n",
       "      (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (tab_resnet): DenseResnet(\n",
       "        (dense_resnet): Sequential(\n",
       "          (lin1): Linear(in_features=162, out_features=128, bias=True)\n",
       "          (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (block_0): BasicBlock(\n",
       "            (lin1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky_relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (dp): Dropout(p=0.1, inplace=False)\n",
       "            (lin2): Linear(in_features=64, out_features=64, bias=True)\n",
       "            (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (resize): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (block_1): BasicBlock(\n",
       "            (lin1): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (leaky_relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            (dp): Dropout(p=0.1, inplace=False)\n",
       "            (lin2): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (resize): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, objective=\"binary\", metrics=[Accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|| 172/172 [00:06<00:00, 26.32it/s, loss=0.415, metrics={'acc': 0.8016}]\n",
      "valid: 100%|| 20/20 [00:00<00:00, 74.72it/s, loss=0.364, metrics={'acc': 0.8044}]\n",
      "epoch 2: 100%|| 172/172 [00:06<00:00, 26.31it/s, loss=0.372, metrics={'acc': 0.8249}]\n",
      "valid: 100%|| 20/20 [00:00<00:00, 76.28it/s, loss=0.356, metrics={'acc': 0.8256}]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(X_wide=X_wide, X_tab=X_tab, target=target, val_split=0.1, n_epochs=2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"models_dir/model.t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to fine-tune the model components, and in the case of the `deeptabular` component, we will fine-tune the resnet-blocks and the linear layer but NOT the embeddings.\n",
    "\n",
    "For this, we need to access the model component's children: `deeptabular` $\\rightarrow$ `tab_resnet` $\\rightarrow$ `dense_resnet` $\\rightarrow$ `blocks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can just load the model as any pytorch model or use the Trainer's staticmethod `load_model`\n",
    "model = Trainer.load_model(\"models_dir/model.t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_lin_layers = list(model.deeptabular.children())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_deep_layers = list(\n",
    "    list(list(list(model.deeptabular.children())[0].children())[2].children())[\n",
    "        0\n",
    "    ].children()\n",
    ")[::-1][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_layers = [tab_lin_layers] + tab_deep_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=32, out_features=1, bias=True),\n",
       " BasicBlock(\n",
       "   (lin1): Linear(in_features=64, out_features=32, bias=True)\n",
       "   (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (leaky_relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "   (dp): Dropout(p=0.1, inplace=False)\n",
       "   (lin2): Linear(in_features=32, out_features=32, bias=True)\n",
       "   (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (resize): Sequential(\n",
       "     (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "     (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " BasicBlock(\n",
       "   (lin1): Linear(in_features=128, out_features=64, bias=True)\n",
       "   (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (leaky_relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "   (dp): Dropout(p=0.1, inplace=False)\n",
       "   (lin2): Linear(in_features=64, out_features=64, bias=True)\n",
       "   (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (resize): Sequential(\n",
       "     (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "     (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trainer = Trainer(model, objective=\"binary\", metrics=[Accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1374 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training wide for 2 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|| 1374/1374 [00:09<00:00, 150.31it/s, loss=0.421, metrics={'acc': 0.7995}]\n",
      "epoch 2: 100%|| 1374/1374 [00:08<00:00, 160.97it/s, loss=0.361, metrics={'acc': 0.8158}]\n",
      "  0%|          | 0/1374 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training deeptabular, layer 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|| 1374/1374 [00:23<00:00, 58.62it/s, loss=0.385, metrics={'acc': 0.8172}]\n",
      "  0%|          | 0/1374 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training deeptabular, layer 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|| 1374/1374 [00:26<00:00, 51.08it/s, loss=0.373, metrics={'acc': 0.8193}]\n",
      "  0%|          | 0/1374 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training deeptabular, layer 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|| 1374/1374 [00:24<00:00, 55.97it/s, loss=0.368, metrics={'acc': 0.8207}]\n",
      "  0%|          | 0/1374 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning of individual components completed. Training the whole model for 2 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|| 1374/1374 [00:33<00:00, 41.35it/s, loss=0.352, metrics={'acc': 0.8373}]\n",
      "valid: 100%|| 153/153 [00:01<00:00, 113.01it/s, loss=0.35, metrics={'acc': 0.8368}] \n",
      "epoch 2: 100%|| 1374/1374 [00:31<00:00, 43.85it/s, loss=0.344, metrics={'acc': 0.8398}]\n",
      "valid: 100%|| 153/153 [00:01<00:00, 129.62it/s, loss=0.348, metrics={'acc': 0.8395}]\n"
     ]
    }
   ],
   "source": [
    "new_trainer.fit(\n",
    "    X_wide=X_wide, \n",
    "    X_tab=X_tab, \n",
    "    target=target, \n",
    "    val_split=0.1, \n",
    "    finetune=True, \n",
    "    finetune_epochs=2, \n",
    "    finetune_deeptabular_gradual=True,\n",
    "    finetune_deeptabular_layers = tab_layers,\n",
    "    finetune_deeptabular_max_lr = 0.01,\n",
    "    n_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Custom model\n",
    "\n",
    "So far we have used the components that come with `pytorch-widedee`. However, as I mentioned in the first post, it is very likely that the user wants to use custom models for the `deeptext` and `deepimage` components. This is easily attainable by...well...simply passing your own model. \n",
    "\n",
    "You should just remember that the model must return the last layer of activations (and NOT the predictions) and must contained an attribute called `output_dim` with the output dimension of  that last layer. \n",
    "\n",
    "For example, let's say we want to use as `deeptext` a **very** simple stack of 2 bidirectional GRUs. Let's see how to do such a thing with the airbnb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary contains 2192 tokens\n",
      "Indexing word vectors...\n",
      "Loaded 400000 word vectors\n",
      "Preparing embeddings matrix...\n",
      "2175 words in the vocabulary had data/glove.6B/glove.6B.100d.txt vectors and appear more than 5 times\n",
      "Reading Images from data/airbnb/property_picture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 39/1001 [00:00<00:02, 389.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1001/1001 [00:02<00:00, 381.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing normalisation metrics\n"
     ]
    }
   ],
   "source": [
    "crossed_cols = [('property_type', 'room_type')]\n",
    "\n",
    "already_dummies = [c for c in airbnb.columns if 'amenity' in c] + ['has_house_rules']\n",
    "\n",
    "wide_cols = ['is_location_exact', 'property_type', 'room_type', 'host_gender',\n",
    "'instant_bookable'] + already_dummies\n",
    "\n",
    "cat_embed_cols = [(c, 16) for c in airbnb.columns if 'catg' in c] + \\\n",
    "    [('neighbourhood_cleansed', 64), ('cancellation_policy', 16)]\n",
    "\n",
    "continuous_cols = ['latitude', 'longitude', 'security_deposit', 'extra_people']\n",
    "\n",
    "already_standard = ['latitude', 'longitude']\n",
    "\n",
    "text_col = 'description'\n",
    "\n",
    "img_col = 'id'\n",
    "word_vectors_path = 'data/glove.6B/glove.6B.100d.txt'\n",
    "\n",
    "img_path = 'data/airbnb/property_picture'\n",
    "\n",
    "target_col = 'yield'\n",
    "\n",
    "target = airbnb[target_col].values\n",
    "\n",
    "wide_preprocessor = WidePreprocessor(wide_cols=wide_cols, crossed_cols=crossed_cols)\n",
    "X_wide = wide_preprocessor.fit_transform(airbnb)\n",
    "\n",
    "tab_preprocessor = TabPreprocessor(embed_cols=cat_embed_cols, continuous_cols=continuous_cols)\n",
    "X_tab = tab_preprocessor.fit_transform(airbnb)\n",
    "\n",
    "text_preprocessor = TextPreprocessor(word_vectors_path=word_vectors_path, text_col=text_col)\n",
    "X_text = text_preprocessor.fit_transform(airbnb)\n",
    "\n",
    "image_processor = ImagePreprocessor(img_col = img_col, img_path = img_path)\n",
    "X_images = image_processor.fit_transform(airbnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class MyDeepText(nn.Module):\n",
    "    def __init__(self, vocab_size, padding_idx=1, embed_dim=100, hidden_dim=64):\n",
    "        super(MyDeepText, self).__init__()\n",
    "\n",
    "        # word/token embeddings\n",
    "        self.word_embed = nn.Embedding(\n",
    "            vocab_size, embed_dim, padding_idx=padding_idx\n",
    "        )\n",
    "\n",
    "        # stack of RNNs\n",
    "        self.rnn = nn.GRU(\n",
    "            embed_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        # Remember, this must be defined. If not WideDeep will through an error\n",
    "        self.output_dim = hidden_dim * 2\n",
    "\n",
    "    def forward(self, X):\n",
    "        embed = self.word_embed(X.long())\n",
    "        o, h = self.rnn(embed)\n",
    "        return torch.cat((h[-2], h[-1]), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from here, \"*proceed as usual*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = Wide(wide_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "deeptabular = TabMlp( \n",
    "    mlp_hidden_dims=[64,32],\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    embed_input=tab_preprocessor.embeddings_input,\n",
    "    continuous_cols=continuous_cols\n",
    ")\n",
    "mydeeptext = MyDeepText(vocab_size=len(text_preprocessor.vocab.itos))\n",
    "model = WideDeep(wide=wide, deeptabular=deeptabular, deeptext=mydeeptext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WideDeep(\n",
       "  (wide): Wide(\n",
       "    (wide_linear): Embedding(357, 1, padding_idx=0)\n",
       "  )\n",
       "  (deeptabular): Sequential(\n",
       "    (0): TabMlp(\n",
       "      (embed_layers): ModuleDict(\n",
       "        (emb_layer_accommodates_catg): Embedding(4, 16, padding_idx=0)\n",
       "        (emb_layer_bathrooms_catg): Embedding(4, 16, padding_idx=0)\n",
       "        (emb_layer_bedrooms_catg): Embedding(5, 16, padding_idx=0)\n",
       "        (emb_layer_beds_catg): Embedding(5, 16, padding_idx=0)\n",
       "        (emb_layer_cancellation_policy): Embedding(6, 16, padding_idx=0)\n",
       "        (emb_layer_guests_included_catg): Embedding(4, 16, padding_idx=0)\n",
       "        (emb_layer_host_listings_count_catg): Embedding(5, 16, padding_idx=0)\n",
       "        (emb_layer_minimum_nights_catg): Embedding(4, 16, padding_idx=0)\n",
       "        (emb_layer_neighbourhood_cleansed): Embedding(33, 64, padding_idx=0)\n",
       "      )\n",
       "      (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (tab_mlp): MLP(\n",
       "        (mlp): Sequential(\n",
       "          (dense_layer_0): Sequential(\n",
       "            (0): Dropout(p=0.1, inplace=False)\n",
       "            (1): Linear(in_features=196, out_features=64, bias=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (dense_layer_1): Sequential(\n",
       "            (0): Dropout(p=0.1, inplace=False)\n",
       "            (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (deeptext): Sequential(\n",
       "    (0): MyDeepText(\n",
       "      (word_embed): Embedding(2192, 100, padding_idx=1)\n",
       "      (rnn): GRU(100, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, objective=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|| 13/13 [00:03<00:00,  3.77it/s, loss=1.79e+4]\n",
      "valid: 100%|| 4/4 [00:00<00:00, 13.34it/s, loss=1.49e+4]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(X_wide=X_wide, X_tab=X_tab, X_text=X_text, target=target, n_epochs=1, batch_size=64, val_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "In this second post I tried to illustrate in detail the different functionalities of the `pytorch-widedeep` package, and how these can be used to customize each of the four potential components of the `WideDeep` model that can be built with `pytorch-widedeep`. I have also describe the warm-up routines that can be used to \"warm-up\" each individual component before the joined training and finally, how custom models, \"external\" to `pytorch-widedeep` can be used in combination with the package. \n",
    "\n",
    "However, this is not the end of the journey. As you will have seen, there is an \"*imbalance in the `pytorch-widedeep` force*\", in the sense that while fully pre-trained models are incorporated for the `deepimage` component, this is not the case for the `deeptext` component, where only pre-trained word embeddings are considered. Of course, as illustrated in Section 4, you could build your own pre-trained `deeptext` component and pass it to the `WideDeep` constructor class, but eventually, I want to allow that option within the package. \n",
    "\n",
    "This means that eventually I will need to integrate the library with some of the pre-trained Language models available or simply code a custom version for `pytorch-widedeep`.\n",
    "\n",
    "One the other hand, I want to bring more DL models for the `deeptabular` components, such as [TabNet](https://arxiv.org/pdf/1908.07442.pdf). There is already a fantastic [`Pytorch` implementation](https://github.com/dreamquark-ai/tabnet) which I highly recommend. \n",
    "\n",
    "If you made it this far, thanks for reading! And if you use the package, let me know your thoughts!\n",
    "\n",
    "#### References\n",
    "\n",
    "[1] Tsung-Yi Lin, Priya Goyal, Ross Girshick, et al., 2018: Focal Loss for Dense Object Detection. [arXiv:1708.02002v2](https://arxiv.org/pdf/1708.02002.pdf)\n",
    "\n",
    "[3] Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm. Bjarke Felbo, Alan Mislove, Anders Sgaard, et al., 2017. [arXiv:1708.00524](https://arxiv.org/abs/1708.00524)\n",
    "\n",
    "[3] Universal Language Model Fine-tuning for Text Classification. Jeremy Howard, Sebastian Ruder, 2018 [arXiv:1801.06146v5](https://arxiv.org/abs/1801.06146)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
